2023-01-18 01:52:48,303 ----------------------------------------------------------------------------------------------------
2023-01-18 01:52:48,304 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)
  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=31, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2023-01-18 01:52:48,304 ----------------------------------------------------------------------------------------------------
2023-01-18 01:52:48,305 Corpus: "Corpus: 343 train + 99 dev + 50 test sentences"
2023-01-18 01:52:48,306 ----------------------------------------------------------------------------------------------------
2023-01-18 01:52:48,306 Parameters:
2023-01-18 01:52:48,306  - learning_rate: "0.100000"
2023-01-18 01:52:48,307  - mini_batch_size: "32"
2023-01-18 01:52:48,307  - patience: "3"
2023-01-18 01:52:48,308  - anneal_factor: "0.5"
2023-01-18 01:52:48,308  - max_epochs: "50"
2023-01-18 01:52:48,309  - shuffle: "True"
2023-01-18 01:52:48,309  - train_with_dev: "False"
2023-01-18 01:52:48,309  - batch_growth_annealing: "False"
2023-01-18 01:52:48,310 ----------------------------------------------------------------------------------------------------
2023-01-18 01:52:48,310 Model training base path: "/home/mchou001/university-classifier"
2023-01-18 01:52:48,311 ----------------------------------------------------------------------------------------------------
2023-01-18 01:52:48,311 Device: cuda:0
2023-01-18 01:52:48,312 ----------------------------------------------------------------------------------------------------
2023-01-18 01:52:48,312 Embeddings storage mode: gpu
2023-01-18 01:52:48,312 ----------------------------------------------------------------------------------------------------
2023-01-18 01:52:48,861 epoch 1 - iter 1/11 - loss 3.67708581 - samples/sec: 58.64 - lr: 0.100000
2023-01-18 01:52:49,204 epoch 1 - iter 2/11 - loss 3.23409675 - samples/sec: 93.72 - lr: 0.100000
2023-01-18 01:52:49,526 epoch 1 - iter 3/11 - loss 2.94160532 - samples/sec: 99.86 - lr: 0.100000
2023-01-18 01:52:49,854 epoch 1 - iter 4/11 - loss 2.71415965 - samples/sec: 97.71 - lr: 0.100000
2023-01-18 01:52:50,106 epoch 1 - iter 5/11 - loss 2.64861890 - samples/sec: 127.48 - lr: 0.100000
2023-01-18 01:52:50,483 epoch 1 - iter 6/11 - loss 2.57152959 - samples/sec: 85.15 - lr: 0.100000
2023-01-18 01:52:50,808 epoch 1 - iter 7/11 - loss 2.47606812 - samples/sec: 98.86 - lr: 0.100000
2023-01-18 01:52:51,408 epoch 1 - iter 8/11 - loss 2.39581159 - samples/sec: 53.44 - lr: 0.100000
2023-01-18 01:52:51,961 epoch 1 - iter 9/11 - loss 2.29368688 - samples/sec: 58.05 - lr: 0.100000
2023-01-18 01:52:52,278 epoch 1 - iter 10/11 - loss 2.22113213 - samples/sec: 101.33 - lr: 0.100000
2023-01-18 01:52:52,530 epoch 1 - iter 11/11 - loss 2.18401664 - samples/sec: 127.27 - lr: 0.100000
2023-01-18 01:52:52,531 ----------------------------------------------------------------------------------------------------
2023-01-18 01:52:52,532 EPOCH 1 done: loss 2.1840 - lr 0.100000
2023-01-18 01:52:54,246 Evaluating as a multi-label problem: False
2023-01-18 01:52:54,266 DEV : loss 1.6160402297973633 - f1-score (micro avg)  0.0238
2023-01-18 01:52:54,272 BAD EPOCHS (no improvement): 0
2023-01-18 01:52:54,275 saving best model
2023-01-18 01:52:59,245 ----------------------------------------------------------------------------------------------------
2023-01-18 01:52:59,478 epoch 2 - iter 1/11 - loss 1.62344853 - samples/sec: 138.20 - lr: 0.100000
2023-01-18 01:52:59,620 epoch 2 - iter 2/11 - loss 1.75934599 - samples/sec: 226.87 - lr: 0.100000
2023-01-18 01:52:59,753 epoch 2 - iter 3/11 - loss 1.73614457 - samples/sec: 243.22 - lr: 0.100000
2023-01-18 01:52:59,885 epoch 2 - iter 4/11 - loss 1.75075312 - samples/sec: 244.34 - lr: 0.100000
2023-01-18 01:53:00,042 epoch 2 - iter 5/11 - loss 1.72601389 - samples/sec: 204.86 - lr: 0.100000
2023-01-18 01:53:00,191 epoch 2 - iter 6/11 - loss 1.73014461 - samples/sec: 217.02 - lr: 0.100000
2023-01-18 01:53:00,391 epoch 2 - iter 7/11 - loss 1.69781881 - samples/sec: 160.74 - lr: 0.100000
2023-01-18 01:53:00,530 epoch 2 - iter 8/11 - loss 1.70842722 - samples/sec: 231.76 - lr: 0.100000
2023-01-18 01:53:00,685 epoch 2 - iter 9/11 - loss 1.70134159 - samples/sec: 208.48 - lr: 0.100000
2023-01-18 01:53:00,925 epoch 2 - iter 10/11 - loss 1.68332316 - samples/sec: 133.91 - lr: 0.100000
2023-01-18 01:53:01,041 epoch 2 - iter 11/11 - loss 1.67568820 - samples/sec: 279.25 - lr: 0.100000
2023-01-18 01:53:01,042 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:01,042 EPOCH 2 done: loss 1.6757 - lr 0.100000
2023-01-18 01:53:01,855 Evaluating as a multi-label problem: False
2023-01-18 01:53:01,874 DEV : loss 1.4312613010406494 - f1-score (micro avg)  0.1056
2023-01-18 01:53:01,879 BAD EPOCHS (no improvement): 0
2023-01-18 01:53:01,880 saving best model
2023-01-18 01:53:06,961 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:07,101 epoch 3 - iter 1/11 - loss 1.47842761 - samples/sec: 231.32 - lr: 0.100000
2023-01-18 01:53:07,258 epoch 3 - iter 2/11 - loss 1.53085983 - samples/sec: 205.53 - lr: 0.100000
2023-01-18 01:53:07,484 epoch 3 - iter 3/11 - loss 1.49521994 - samples/sec: 142.38 - lr: 0.100000
2023-01-18 01:53:07,728 epoch 3 - iter 4/11 - loss 1.48599665 - samples/sec: 131.81 - lr: 0.100000
2023-01-18 01:53:07,892 epoch 3 - iter 5/11 - loss 1.48128518 - samples/sec: 197.33 - lr: 0.100000
2023-01-18 01:53:08,092 epoch 3 - iter 6/11 - loss 1.48308347 - samples/sec: 161.10 - lr: 0.100000
2023-01-18 01:53:08,225 epoch 3 - iter 7/11 - loss 1.47799250 - samples/sec: 243.39 - lr: 0.100000
2023-01-18 01:53:08,370 epoch 3 - iter 8/11 - loss 1.46464858 - samples/sec: 222.41 - lr: 0.100000
2023-01-18 01:53:08,571 epoch 3 - iter 9/11 - loss 1.44630418 - samples/sec: 159.55 - lr: 0.100000
2023-01-18 01:53:08,711 epoch 3 - iter 10/11 - loss 1.44233910 - samples/sec: 231.17 - lr: 0.100000
2023-01-18 01:53:08,820 epoch 3 - iter 11/11 - loss 1.43855794 - samples/sec: 295.37 - lr: 0.100000
2023-01-18 01:53:08,821 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:08,821 EPOCH 3 done: loss 1.4386 - lr 0.100000
2023-01-18 01:53:10,008 Evaluating as a multi-label problem: False
2023-01-18 01:53:10,024 DEV : loss 1.2385786771774292 - f1-score (micro avg)  0.0472
2023-01-18 01:53:10,029 BAD EPOCHS (no improvement): 1
2023-01-18 01:53:10,031 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:10,186 epoch 4 - iter 1/11 - loss 1.29950098 - samples/sec: 209.00 - lr: 0.100000
2023-01-18 01:53:10,385 epoch 4 - iter 2/11 - loss 1.35594719 - samples/sec: 161.77 - lr: 0.100000
2023-01-18 01:53:10,524 epoch 4 - iter 3/11 - loss 1.30726748 - samples/sec: 231.02 - lr: 0.100000
2023-01-18 01:53:10,750 epoch 4 - iter 4/11 - loss 1.29572906 - samples/sec: 142.46 - lr: 0.100000
2023-01-18 01:53:10,988 epoch 4 - iter 5/11 - loss 1.28486922 - samples/sec: 135.17 - lr: 0.100000
2023-01-18 01:53:11,126 epoch 4 - iter 6/11 - loss 1.27856582 - samples/sec: 233.03 - lr: 0.100000
2023-01-18 01:53:11,282 epoch 4 - iter 7/11 - loss 1.26617840 - samples/sec: 206.19 - lr: 0.100000
2023-01-18 01:53:11,424 epoch 4 - iter 8/11 - loss 1.25047964 - samples/sec: 226.90 - lr: 0.100000
2023-01-18 01:53:11,550 epoch 4 - iter 9/11 - loss 1.24171046 - samples/sec: 257.67 - lr: 0.100000
2023-01-18 01:53:11,688 epoch 4 - iter 10/11 - loss 1.24055499 - samples/sec: 231.84 - lr: 0.100000
2023-01-18 01:53:11,806 epoch 4 - iter 11/11 - loss 1.23292660 - samples/sec: 275.34 - lr: 0.100000
2023-01-18 01:53:11,807 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:11,807 EPOCH 4 done: loss 1.2329 - lr 0.100000
2023-01-18 01:53:12,619 Evaluating as a multi-label problem: False
2023-01-18 01:53:12,635 DEV : loss 0.9460089802742004 - f1-score (micro avg)  0.1038
2023-01-18 01:53:12,640 BAD EPOCHS (no improvement): 2
2023-01-18 01:53:12,642 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:12,782 epoch 5 - iter 1/11 - loss 1.14550177 - samples/sec: 229.41 - lr: 0.100000
2023-01-18 01:53:12,917 epoch 5 - iter 2/11 - loss 1.13045043 - samples/sec: 239.05 - lr: 0.100000
2023-01-18 01:53:13,110 epoch 5 - iter 3/11 - loss 1.12869269 - samples/sec: 166.07 - lr: 0.100000
2023-01-18 01:53:13,247 epoch 5 - iter 4/11 - loss 1.13167282 - samples/sec: 237.23 - lr: 0.100000
2023-01-18 01:53:13,395 epoch 5 - iter 5/11 - loss 1.10594316 - samples/sec: 217.17 - lr: 0.100000
2023-01-18 01:53:13,529 epoch 5 - iter 6/11 - loss 1.10107214 - samples/sec: 240.60 - lr: 0.100000
2023-01-18 01:53:13,672 epoch 5 - iter 7/11 - loss 1.09724304 - samples/sec: 226.54 - lr: 0.100000
2023-01-18 01:53:13,876 epoch 5 - iter 8/11 - loss 1.09656564 - samples/sec: 157.96 - lr: 0.100000
2023-01-18 01:53:14,110 epoch 5 - iter 9/11 - loss 1.08158969 - samples/sec: 137.12 - lr: 0.100000
2023-01-18 01:53:14,272 epoch 5 - iter 10/11 - loss 1.06441788 - samples/sec: 198.64 - lr: 0.100000
2023-01-18 01:53:14,383 epoch 5 - iter 11/11 - loss 1.05390628 - samples/sec: 292.03 - lr: 0.100000
2023-01-18 01:53:14,384 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:14,385 EPOCH 5 done: loss 1.0539 - lr 0.100000
2023-01-18 01:53:15,214 Evaluating as a multi-label problem: False
2023-01-18 01:53:15,231 DEV : loss 0.788469672203064 - f1-score (micro avg)  0.1924
2023-01-18 01:53:15,236 BAD EPOCHS (no improvement): 0
2023-01-18 01:53:15,237 saving best model
2023-01-18 01:53:20,367 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:20,534 epoch 6 - iter 1/11 - loss 0.92537704 - samples/sec: 194.28 - lr: 0.100000
2023-01-18 01:53:20,667 epoch 6 - iter 2/11 - loss 0.98513217 - samples/sec: 241.82 - lr: 0.100000
2023-01-18 01:53:20,864 epoch 6 - iter 3/11 - loss 0.95502234 - samples/sec: 163.48 - lr: 0.100000
2023-01-18 01:53:21,064 epoch 6 - iter 4/11 - loss 0.92897098 - samples/sec: 160.76 - lr: 0.100000
2023-01-18 01:53:21,207 epoch 6 - iter 5/11 - loss 0.92540137 - samples/sec: 226.01 - lr: 0.100000
2023-01-18 01:53:21,358 epoch 6 - iter 6/11 - loss 0.92076167 - samples/sec: 214.05 - lr: 0.100000
2023-01-18 01:53:21,498 epoch 6 - iter 7/11 - loss 0.90437305 - samples/sec: 229.35 - lr: 0.100000
2023-01-18 01:53:21,636 epoch 6 - iter 8/11 - loss 0.89125084 - samples/sec: 234.17 - lr: 0.100000
2023-01-18 01:53:21,872 epoch 6 - iter 9/11 - loss 0.89542644 - samples/sec: 136.59 - lr: 0.100000
2023-01-18 01:53:22,095 epoch 6 - iter 10/11 - loss 0.88968705 - samples/sec: 144.24 - lr: 0.100000
2023-01-18 01:53:22,199 epoch 6 - iter 11/11 - loss 0.88311861 - samples/sec: 309.95 - lr: 0.100000
2023-01-18 01:53:22,201 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:22,201 EPOCH 6 done: loss 0.8831 - lr 0.100000
2023-01-18 01:53:23,038 Evaluating as a multi-label problem: False
2023-01-18 01:53:23,057 DEV : loss 0.6502238512039185 - f1-score (micro avg)  0.285
2023-01-18 01:53:23,061 BAD EPOCHS (no improvement): 0
2023-01-18 01:53:23,063 saving best model
2023-01-18 01:53:28,052 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:28,195 epoch 7 - iter 1/11 - loss 0.78036988 - samples/sec: 225.79 - lr: 0.100000
2023-01-18 01:53:28,400 epoch 7 - iter 2/11 - loss 0.72335176 - samples/sec: 157.69 - lr: 0.100000
2023-01-18 01:53:28,552 epoch 7 - iter 3/11 - loss 0.72680261 - samples/sec: 212.33 - lr: 0.100000
2023-01-18 01:53:28,676 epoch 7 - iter 4/11 - loss 0.74996513 - samples/sec: 260.43 - lr: 0.100000
2023-01-18 01:53:28,831 epoch 7 - iter 5/11 - loss 0.74517661 - samples/sec: 207.24 - lr: 0.100000
2023-01-18 01:53:28,969 epoch 7 - iter 6/11 - loss 0.73499824 - samples/sec: 233.76 - lr: 0.100000
2023-01-18 01:53:29,112 epoch 7 - iter 7/11 - loss 0.73316206 - samples/sec: 226.23 - lr: 0.100000
2023-01-18 01:53:29,240 epoch 7 - iter 8/11 - loss 0.72339532 - samples/sec: 252.51 - lr: 0.100000
2023-01-18 01:53:29,459 epoch 7 - iter 9/11 - loss 0.73379333 - samples/sec: 146.61 - lr: 0.100000
2023-01-18 01:53:29,593 epoch 7 - iter 10/11 - loss 0.73226779 - samples/sec: 240.61 - lr: 0.100000
2023-01-18 01:53:29,797 epoch 7 - iter 11/11 - loss 0.72688886 - samples/sec: 157.61 - lr: 0.100000
2023-01-18 01:53:29,799 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:29,799 EPOCH 7 done: loss 0.7269 - lr 0.100000
2023-01-18 01:53:30,636 Evaluating as a multi-label problem: False
2023-01-18 01:53:30,653 DEV : loss 0.518014669418335 - f1-score (micro avg)  0.3662
2023-01-18 01:53:30,657 BAD EPOCHS (no improvement): 0
2023-01-18 01:53:30,659 saving best model
2023-01-18 01:53:35,685 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:35,897 epoch 8 - iter 1/11 - loss 0.67523123 - samples/sec: 151.64 - lr: 0.100000
2023-01-18 01:53:36,420 epoch 8 - iter 2/11 - loss 0.68492061 - samples/sec: 61.39 - lr: 0.100000
2023-01-18 01:53:36,571 epoch 8 - iter 3/11 - loss 0.65329821 - samples/sec: 214.69 - lr: 0.100000
2023-01-18 01:53:36,805 epoch 8 - iter 4/11 - loss 0.65869591 - samples/sec: 137.43 - lr: 0.100000
2023-01-18 01:53:37,032 epoch 8 - iter 5/11 - loss 0.65455828 - samples/sec: 141.64 - lr: 0.100000
2023-01-18 01:53:37,170 epoch 8 - iter 6/11 - loss 0.66054064 - samples/sec: 234.09 - lr: 0.100000
2023-01-18 01:53:37,309 epoch 8 - iter 7/11 - loss 0.64692224 - samples/sec: 233.43 - lr: 0.100000
2023-01-18 01:53:37,442 epoch 8 - iter 8/11 - loss 0.65583787 - samples/sec: 241.11 - lr: 0.100000
2023-01-18 01:53:37,568 epoch 8 - iter 9/11 - loss 0.64480874 - samples/sec: 258.02 - lr: 0.100000
2023-01-18 01:53:37,722 epoch 8 - iter 10/11 - loss 0.63158075 - samples/sec: 208.41 - lr: 0.100000
2023-01-18 01:53:37,843 epoch 8 - iter 11/11 - loss 0.62385007 - samples/sec: 266.74 - lr: 0.100000
2023-01-18 01:53:37,844 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:37,845 EPOCH 8 done: loss 0.6239 - lr 0.100000
2023-01-18 01:53:38,686 Evaluating as a multi-label problem: False
2023-01-18 01:53:38,703 DEV : loss 0.45472264289855957 - f1-score (micro avg)  0.4933
2023-01-18 01:53:38,708 BAD EPOCHS (no improvement): 0
2023-01-18 01:53:38,710 saving best model
2023-01-18 01:53:43,801 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:43,948 epoch 9 - iter 1/11 - loss 0.60875079 - samples/sec: 219.76 - lr: 0.100000
2023-01-18 01:53:44,103 epoch 9 - iter 2/11 - loss 0.58566577 - samples/sec: 208.57 - lr: 0.100000
2023-01-18 01:53:44,332 epoch 9 - iter 3/11 - loss 0.57856729 - samples/sec: 140.67 - lr: 0.100000
2023-01-18 01:53:44,473 epoch 9 - iter 4/11 - loss 0.57778985 - samples/sec: 229.21 - lr: 0.100000
2023-01-18 01:53:44,676 epoch 9 - iter 5/11 - loss 0.56633490 - samples/sec: 158.51 - lr: 0.100000
2023-01-18 01:53:44,807 epoch 9 - iter 6/11 - loss 0.55947083 - samples/sec: 246.04 - lr: 0.100000
2023-01-18 01:53:44,966 epoch 9 - iter 7/11 - loss 0.55736819 - samples/sec: 202.61 - lr: 0.100000
2023-01-18 01:53:45,208 epoch 9 - iter 8/11 - loss 0.55816289 - samples/sec: 132.81 - lr: 0.100000
2023-01-18 01:53:45,365 epoch 9 - iter 9/11 - loss 0.55391963 - samples/sec: 206.18 - lr: 0.100000
2023-01-18 01:53:45,495 epoch 9 - iter 10/11 - loss 0.55119952 - samples/sec: 248.55 - lr: 0.100000
2023-01-18 01:53:45,615 epoch 9 - iter 11/11 - loss 0.54812357 - samples/sec: 267.42 - lr: 0.100000
2023-01-18 01:53:45,616 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:45,617 EPOCH 9 done: loss 0.5481 - lr 0.100000
2023-01-18 01:53:46,454 Evaluating as a multi-label problem: False
2023-01-18 01:53:46,470 DEV : loss 0.4098021686077118 - f1-score (micro avg)  0.5476
2023-01-18 01:53:46,475 BAD EPOCHS (no improvement): 0
2023-01-18 01:53:46,477 saving best model
2023-01-18 01:53:51,466 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:51,678 epoch 10 - iter 1/11 - loss 0.46308382 - samples/sec: 151.95 - lr: 0.100000
2023-01-18 01:53:51,806 epoch 10 - iter 2/11 - loss 0.45295926 - samples/sec: 253.28 - lr: 0.100000
2023-01-18 01:53:51,962 epoch 10 - iter 3/11 - loss 0.48535586 - samples/sec: 206.56 - lr: 0.100000
2023-01-18 01:53:52,119 epoch 10 - iter 4/11 - loss 0.49441180 - samples/sec: 204.64 - lr: 0.100000
2023-01-18 01:53:52,360 epoch 10 - iter 5/11 - loss 0.50947775 - samples/sec: 133.31 - lr: 0.100000
2023-01-18 01:53:52,566 epoch 10 - iter 6/11 - loss 0.50831215 - samples/sec: 156.51 - lr: 0.100000
2023-01-18 01:53:52,704 epoch 10 - iter 7/11 - loss 0.49646198 - samples/sec: 233.49 - lr: 0.100000
2023-01-18 01:53:52,836 epoch 10 - iter 8/11 - loss 0.48865254 - samples/sec: 244.49 - lr: 0.100000
2023-01-18 01:53:52,977 epoch 10 - iter 9/11 - loss 0.48508346 - samples/sec: 228.15 - lr: 0.100000
2023-01-18 01:53:53,115 epoch 10 - iter 10/11 - loss 0.47653977 - samples/sec: 234.26 - lr: 0.100000
2023-01-18 01:53:53,246 epoch 10 - iter 11/11 - loss 0.47507177 - samples/sec: 246.56 - lr: 0.100000
2023-01-18 01:53:53,247 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:53,247 EPOCH 10 done: loss 0.4751 - lr 0.100000
2023-01-18 01:53:54,102 Evaluating as a multi-label problem: False
2023-01-18 01:53:54,119 DEV : loss 0.3309646248817444 - f1-score (micro avg)  0.6894
2023-01-18 01:53:54,123 BAD EPOCHS (no improvement): 0
2023-01-18 01:53:54,125 saving best model
2023-01-18 01:53:59,084 ----------------------------------------------------------------------------------------------------
2023-01-18 01:53:59,231 epoch 11 - iter 1/11 - loss 0.44958094 - samples/sec: 219.40 - lr: 0.100000
2023-01-18 01:53:59,433 epoch 11 - iter 2/11 - loss 0.44977376 - samples/sec: 159.78 - lr: 0.100000
2023-01-18 01:53:59,564 epoch 11 - iter 3/11 - loss 0.43291014 - samples/sec: 245.29 - lr: 0.100000
2023-01-18 01:53:59,704 epoch 11 - iter 4/11 - loss 0.44722368 - samples/sec: 230.94 - lr: 0.100000
2023-01-18 01:53:59,907 epoch 11 - iter 5/11 - loss 0.42116681 - samples/sec: 158.08 - lr: 0.100000
2023-01-18 01:54:00,050 epoch 11 - iter 6/11 - loss 0.41451528 - samples/sec: 225.47 - lr: 0.100000
2023-01-18 01:54:00,290 epoch 11 - iter 7/11 - loss 0.41317904 - samples/sec: 134.20 - lr: 0.100000
2023-01-18 01:54:00,431 epoch 11 - iter 8/11 - loss 0.41217950 - samples/sec: 228.09 - lr: 0.100000
2023-01-18 01:54:00,565 epoch 11 - iter 9/11 - loss 0.41010105 - samples/sec: 240.63 - lr: 0.100000
2023-01-18 01:54:00,724 epoch 11 - iter 10/11 - loss 0.40610993 - samples/sec: 203.15 - lr: 0.100000
2023-01-18 01:54:00,832 epoch 11 - iter 11/11 - loss 0.40737785 - samples/sec: 296.89 - lr: 0.100000
2023-01-18 01:54:00,833 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:00,834 EPOCH 11 done: loss 0.4074 - lr 0.100000
2023-01-18 01:54:01,743 Evaluating as a multi-label problem: False
2023-01-18 01:54:01,761 DEV : loss 0.27962568402290344 - f1-score (micro avg)  0.6628
2023-01-18 01:54:01,766 BAD EPOCHS (no improvement): 1
2023-01-18 01:54:01,811 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:01,958 epoch 12 - iter 1/11 - loss 0.36824289 - samples/sec: 220.85 - lr: 0.100000
2023-01-18 01:54:02,121 epoch 12 - iter 2/11 - loss 0.39128331 - samples/sec: 197.48 - lr: 0.100000
2023-01-18 01:54:02,737 epoch 12 - iter 3/11 - loss 0.36178326 - samples/sec: 51.97 - lr: 0.100000
2023-01-18 01:54:02,886 epoch 12 - iter 4/11 - loss 0.36158438 - samples/sec: 217.89 - lr: 0.100000
2023-01-18 01:54:03,126 epoch 12 - iter 5/11 - loss 0.38808458 - samples/sec: 133.91 - lr: 0.100000
2023-01-18 01:54:03,258 epoch 12 - iter 6/11 - loss 0.38162129 - samples/sec: 245.24 - lr: 0.100000
2023-01-18 01:54:03,391 epoch 12 - iter 7/11 - loss 0.36869462 - samples/sec: 243.27 - lr: 0.100000
2023-01-18 01:54:03,544 epoch 12 - iter 8/11 - loss 0.36108984 - samples/sec: 210.42 - lr: 0.100000
2023-01-18 01:54:03,674 epoch 12 - iter 9/11 - loss 0.35482885 - samples/sec: 247.62 - lr: 0.100000
2023-01-18 01:54:03,872 epoch 12 - iter 10/11 - loss 0.35215437 - samples/sec: 162.22 - lr: 0.100000
2023-01-18 01:54:04,043 epoch 12 - iter 11/11 - loss 0.35125647 - samples/sec: 189.18 - lr: 0.100000
2023-01-18 01:54:04,044 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:04,044 EPOCH 12 done: loss 0.3513 - lr 0.100000
2023-01-18 01:54:04,958 Evaluating as a multi-label problem: False
2023-01-18 01:54:04,975 DEV : loss 0.22729815542697906 - f1-score (micro avg)  0.7422
2023-01-18 01:54:04,980 BAD EPOCHS (no improvement): 0
2023-01-18 01:54:05,025 saving best model
2023-01-18 01:54:10,200 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:10,368 epoch 13 - iter 1/11 - loss 0.28663990 - samples/sec: 192.34 - lr: 0.100000
2023-01-18 01:54:10,512 epoch 13 - iter 2/11 - loss 0.31027423 - samples/sec: 224.61 - lr: 0.100000
2023-01-18 01:54:10,671 epoch 13 - iter 3/11 - loss 0.30288959 - samples/sec: 202.83 - lr: 0.100000
2023-01-18 01:54:10,805 epoch 13 - iter 4/11 - loss 0.32155086 - samples/sec: 240.87 - lr: 0.100000
2023-01-18 01:54:11,033 epoch 13 - iter 5/11 - loss 0.33068972 - samples/sec: 140.97 - lr: 0.100000
2023-01-18 01:54:11,175 epoch 13 - iter 6/11 - loss 0.31998407 - samples/sec: 227.77 - lr: 0.100000
2023-01-18 01:54:11,329 epoch 13 - iter 7/11 - loss 0.31953131 - samples/sec: 209.65 - lr: 0.100000
2023-01-18 01:54:11,468 epoch 13 - iter 8/11 - loss 0.32280463 - samples/sec: 232.96 - lr: 0.100000
2023-01-18 01:54:11,593 epoch 13 - iter 9/11 - loss 0.31979012 - samples/sec: 257.99 - lr: 0.100000
2023-01-18 01:54:11,792 epoch 13 - iter 10/11 - loss 0.31721260 - samples/sec: 161.96 - lr: 0.100000
2023-01-18 01:54:11,996 epoch 13 - iter 11/11 - loss 0.32042882 - samples/sec: 157.50 - lr: 0.100000
2023-01-18 01:54:11,997 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:11,998 EPOCH 13 done: loss 0.3204 - lr 0.100000
2023-01-18 01:54:12,844 Evaluating as a multi-label problem: False
2023-01-18 01:54:12,860 DEV : loss 0.21379052102565765 - f1-score (micro avg)  0.7532
2023-01-18 01:54:12,865 BAD EPOCHS (no improvement): 0
2023-01-18 01:54:12,866 saving best model
2023-01-18 01:54:17,875 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:18,127 epoch 14 - iter 1/11 - loss 0.28443622 - samples/sec: 127.91 - lr: 0.100000
2023-01-18 01:54:18,258 epoch 14 - iter 2/11 - loss 0.27767190 - samples/sec: 247.46 - lr: 0.100000
2023-01-18 01:54:18,394 epoch 14 - iter 3/11 - loss 0.31109299 - samples/sec: 237.95 - lr: 0.100000
2023-01-18 01:54:18,536 epoch 14 - iter 4/11 - loss 0.30697864 - samples/sec: 227.08 - lr: 0.100000
2023-01-18 01:54:18,734 epoch 14 - iter 5/11 - loss 0.30222372 - samples/sec: 162.29 - lr: 0.100000
2023-01-18 01:54:18,936 epoch 14 - iter 6/11 - loss 0.30663093 - samples/sec: 158.78 - lr: 0.100000
2023-01-18 01:54:19,075 epoch 14 - iter 7/11 - loss 0.30414556 - samples/sec: 232.32 - lr: 0.100000
2023-01-18 01:54:19,215 epoch 14 - iter 8/11 - loss 0.30028904 - samples/sec: 231.11 - lr: 0.100000
2023-01-18 01:54:19,439 epoch 14 - iter 9/11 - loss 0.29751536 - samples/sec: 143.19 - lr: 0.100000
2023-01-18 01:54:19,568 epoch 14 - iter 10/11 - loss 0.29349497 - samples/sec: 249.70 - lr: 0.100000
2023-01-18 01:54:19,698 epoch 14 - iter 11/11 - loss 0.28813435 - samples/sec: 250.07 - lr: 0.100000
2023-01-18 01:54:19,699 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:19,699 EPOCH 14 done: loss 0.2881 - lr 0.100000
2023-01-18 01:54:20,555 Evaluating as a multi-label problem: False
2023-01-18 01:54:20,572 DEV : loss 0.20759643614292145 - f1-score (micro avg)  0.7644
2023-01-18 01:54:20,576 BAD EPOCHS (no improvement): 0
2023-01-18 01:54:20,578 saving best model
2023-01-18 01:54:25,617 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:25,752 epoch 15 - iter 1/11 - loss 0.26453980 - samples/sec: 240.20 - lr: 0.100000
2023-01-18 01:54:25,879 epoch 15 - iter 2/11 - loss 0.26759866 - samples/sec: 255.15 - lr: 0.100000
2023-01-18 01:54:26,025 epoch 15 - iter 3/11 - loss 0.26313021 - samples/sec: 220.89 - lr: 0.100000
2023-01-18 01:54:26,177 epoch 15 - iter 4/11 - loss 0.25544390 - samples/sec: 212.62 - lr: 0.100000
2023-01-18 01:54:26,314 epoch 15 - iter 5/11 - loss 0.25706752 - samples/sec: 234.62 - lr: 0.100000
2023-01-18 01:54:26,449 epoch 15 - iter 6/11 - loss 0.24672192 - samples/sec: 239.77 - lr: 0.100000
2023-01-18 01:54:26,602 epoch 15 - iter 7/11 - loss 0.25146854 - samples/sec: 210.41 - lr: 0.100000
2023-01-18 01:54:26,840 epoch 15 - iter 8/11 - loss 0.25655766 - samples/sec: 135.20 - lr: 0.100000
2023-01-18 01:54:27,005 epoch 15 - iter 9/11 - loss 0.25529391 - samples/sec: 194.95 - lr: 0.100000
2023-01-18 01:54:27,208 epoch 15 - iter 10/11 - loss 0.25232891 - samples/sec: 158.89 - lr: 0.100000
2023-01-18 01:54:27,378 epoch 15 - iter 11/11 - loss 0.25629345 - samples/sec: 188.95 - lr: 0.100000
2023-01-18 01:54:27,380 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:27,380 EPOCH 15 done: loss 0.2563 - lr 0.100000
2023-01-18 01:54:28,238 Evaluating as a multi-label problem: False
2023-01-18 01:54:28,256 DEV : loss 0.1704796403646469 - f1-score (micro avg)  0.8024
2023-01-18 01:54:28,260 BAD EPOCHS (no improvement): 0
2023-01-18 01:54:28,264 saving best model
2023-01-18 01:54:33,345 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:33,552 epoch 16 - iter 1/11 - loss 0.24499095 - samples/sec: 155.54 - lr: 0.100000
2023-01-18 01:54:33,697 epoch 16 - iter 2/11 - loss 0.23672031 - samples/sec: 222.67 - lr: 0.100000
2023-01-18 01:54:33,924 epoch 16 - iter 3/11 - loss 0.24312346 - samples/sec: 141.88 - lr: 0.100000
2023-01-18 01:54:34,085 epoch 16 - iter 4/11 - loss 0.24027273 - samples/sec: 200.06 - lr: 0.100000
2023-01-18 01:54:34,701 epoch 16 - iter 5/11 - loss 0.24253924 - samples/sec: 52.14 - lr: 0.100000
2023-01-18 01:54:34,842 epoch 16 - iter 6/11 - loss 0.25170524 - samples/sec: 228.24 - lr: 0.100000
2023-01-18 01:54:34,998 epoch 16 - iter 7/11 - loss 0.24692242 - samples/sec: 206.96 - lr: 0.100000
2023-01-18 01:54:35,125 epoch 16 - iter 8/11 - loss 0.24891486 - samples/sec: 254.02 - lr: 0.100000
2023-01-18 01:54:35,258 epoch 16 - iter 9/11 - loss 0.24603984 - samples/sec: 243.22 - lr: 0.100000
2023-01-18 01:54:35,418 epoch 16 - iter 10/11 - loss 0.24557523 - samples/sec: 201.22 - lr: 0.100000
2023-01-18 01:54:35,530 epoch 16 - iter 11/11 - loss 0.24515063 - samples/sec: 289.97 - lr: 0.100000
2023-01-18 01:54:35,530 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:35,531 EPOCH 16 done: loss 0.2452 - lr 0.100000
2023-01-18 01:54:36,465 Evaluating as a multi-label problem: False
2023-01-18 01:54:36,481 DEV : loss 0.18818697333335876 - f1-score (micro avg)  0.7495
2023-01-18 01:54:36,486 BAD EPOCHS (no improvement): 1
2023-01-18 01:54:36,519 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:36,665 epoch 17 - iter 1/11 - loss 0.25655313 - samples/sec: 221.16 - lr: 0.100000
2023-01-18 01:54:36,824 epoch 17 - iter 2/11 - loss 0.28783853 - samples/sec: 201.94 - lr: 0.100000
2023-01-18 01:54:36,957 epoch 17 - iter 3/11 - loss 0.26898796 - samples/sec: 244.12 - lr: 0.100000
2023-01-18 01:54:37,087 epoch 17 - iter 4/11 - loss 0.25861336 - samples/sec: 247.40 - lr: 0.100000
2023-01-18 01:54:37,226 epoch 17 - iter 5/11 - loss 0.24838256 - samples/sec: 232.54 - lr: 0.100000
2023-01-18 01:54:37,450 epoch 17 - iter 6/11 - loss 0.23899228 - samples/sec: 143.67 - lr: 0.100000
2023-01-18 01:54:37,590 epoch 17 - iter 7/11 - loss 0.24528636 - samples/sec: 229.26 - lr: 0.100000
2023-01-18 01:54:37,799 epoch 17 - iter 8/11 - loss 0.24745477 - samples/sec: 154.44 - lr: 0.100000
2023-01-18 01:54:37,997 epoch 17 - iter 9/11 - loss 0.24826136 - samples/sec: 162.83 - lr: 0.100000
2023-01-18 01:54:38,237 epoch 17 - iter 10/11 - loss 0.25009401 - samples/sec: 133.47 - lr: 0.100000
2023-01-18 01:54:38,361 epoch 17 - iter 11/11 - loss 0.24837910 - samples/sec: 261.12 - lr: 0.100000
2023-01-18 01:54:38,362 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:38,363 EPOCH 17 done: loss 0.2484 - lr 0.100000
2023-01-18 01:54:39,271 Evaluating as a multi-label problem: False
2023-01-18 01:54:39,287 DEV : loss 0.15769509971141815 - f1-score (micro avg)  0.8045
2023-01-18 01:54:39,292 BAD EPOCHS (no improvement): 0
2023-01-18 01:54:39,335 saving best model
2023-01-18 01:54:44,409 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:44,540 epoch 18 - iter 1/11 - loss 0.18054014 - samples/sec: 248.47 - lr: 0.100000
2023-01-18 01:54:44,682 epoch 18 - iter 2/11 - loss 0.22926596 - samples/sec: 227.48 - lr: 0.100000
2023-01-18 01:54:44,845 epoch 18 - iter 3/11 - loss 0.20204466 - samples/sec: 197.86 - lr: 0.100000
2023-01-18 01:54:45,042 epoch 18 - iter 4/11 - loss 0.20309200 - samples/sec: 162.68 - lr: 0.100000
2023-01-18 01:54:45,189 epoch 18 - iter 5/11 - loss 0.19768843 - samples/sec: 220.03 - lr: 0.100000
2023-01-18 01:54:45,341 epoch 18 - iter 6/11 - loss 0.19333990 - samples/sec: 212.57 - lr: 0.100000
2023-01-18 01:54:45,566 epoch 18 - iter 7/11 - loss 0.19001174 - samples/sec: 142.96 - lr: 0.100000
2023-01-18 01:54:45,764 epoch 18 - iter 8/11 - loss 0.19648378 - samples/sec: 162.21 - lr: 0.100000
2023-01-18 01:54:45,921 epoch 18 - iter 9/11 - loss 0.19602478 - samples/sec: 205.87 - lr: 0.100000
2023-01-18 01:54:46,158 epoch 18 - iter 10/11 - loss 0.19714519 - samples/sec: 135.27 - lr: 0.100000
2023-01-18 01:54:46,270 epoch 18 - iter 11/11 - loss 0.20077073 - samples/sec: 289.21 - lr: 0.100000
2023-01-18 01:54:46,271 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:46,272 EPOCH 18 done: loss 0.2008 - lr 0.100000
2023-01-18 01:54:47,117 Evaluating as a multi-label problem: False
2023-01-18 01:54:47,133 DEV : loss 0.150710329413414 - f1-score (micro avg)  0.8018
2023-01-18 01:54:47,138 BAD EPOCHS (no improvement): 1
2023-01-18 01:54:47,140 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:47,345 epoch 19 - iter 1/11 - loss 0.18033680 - samples/sec: 157.08 - lr: 0.100000
2023-01-18 01:54:47,493 epoch 19 - iter 2/11 - loss 0.17537511 - samples/sec: 219.43 - lr: 0.100000
2023-01-18 01:54:47,693 epoch 19 - iter 3/11 - loss 0.17595354 - samples/sec: 161.19 - lr: 0.100000
2023-01-18 01:54:47,845 epoch 19 - iter 4/11 - loss 0.17072380 - samples/sec: 211.07 - lr: 0.100000
2023-01-18 01:54:48,000 epoch 19 - iter 5/11 - loss 0.18982283 - samples/sec: 209.14 - lr: 0.100000
2023-01-18 01:54:48,238 epoch 19 - iter 6/11 - loss 0.19329002 - samples/sec: 135.11 - lr: 0.100000
2023-01-18 01:54:48,381 epoch 19 - iter 7/11 - loss 0.19297093 - samples/sec: 224.84 - lr: 0.100000
2023-01-18 01:54:48,528 epoch 19 - iter 8/11 - loss 0.19231644 - samples/sec: 219.32 - lr: 0.100000
2023-01-18 01:54:48,686 epoch 19 - iter 9/11 - loss 0.19709193 - samples/sec: 204.06 - lr: 0.100000
2023-01-18 01:54:48,816 epoch 19 - iter 10/11 - loss 0.19383222 - samples/sec: 248.07 - lr: 0.100000
2023-01-18 01:54:49,007 epoch 19 - iter 11/11 - loss 0.19533514 - samples/sec: 168.61 - lr: 0.100000
2023-01-18 01:54:49,008 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:49,009 EPOCH 19 done: loss 0.1953 - lr 0.100000
2023-01-18 01:54:49,847 Evaluating as a multi-label problem: False
2023-01-18 01:54:49,864 DEV : loss 0.12240304052829742 - f1-score (micro avg)  0.8196
2023-01-18 01:54:49,868 BAD EPOCHS (no improvement): 0
2023-01-18 01:54:49,870 saving best model
2023-01-18 01:54:54,993 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:55,150 epoch 20 - iter 1/11 - loss 0.16710636 - samples/sec: 205.90 - lr: 0.100000
2023-01-18 01:54:55,644 epoch 20 - iter 2/11 - loss 0.18909816 - samples/sec: 64.91 - lr: 0.100000
2023-01-18 01:54:55,841 epoch 20 - iter 3/11 - loss 0.18624734 - samples/sec: 163.29 - lr: 0.100000
2023-01-18 01:54:56,036 epoch 20 - iter 4/11 - loss 0.20178629 - samples/sec: 164.91 - lr: 0.100000
2023-01-18 01:54:56,258 epoch 20 - iter 5/11 - loss 0.19414010 - samples/sec: 144.78 - lr: 0.100000
2023-01-18 01:54:56,495 epoch 20 - iter 6/11 - loss 0.19920872 - samples/sec: 135.81 - lr: 0.100000
2023-01-18 01:54:56,624 epoch 20 - iter 7/11 - loss 0.19373261 - samples/sec: 250.43 - lr: 0.100000
2023-01-18 01:54:56,775 epoch 20 - iter 8/11 - loss 0.19559210 - samples/sec: 215.07 - lr: 0.100000
2023-01-18 01:54:56,916 epoch 20 - iter 9/11 - loss 0.19790221 - samples/sec: 227.68 - lr: 0.100000
2023-01-18 01:54:57,059 epoch 20 - iter 10/11 - loss 0.19370978 - samples/sec: 226.78 - lr: 0.100000
2023-01-18 01:54:57,174 epoch 20 - iter 11/11 - loss 0.19219645 - samples/sec: 279.95 - lr: 0.100000
2023-01-18 01:54:57,175 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:57,175 EPOCH 20 done: loss 0.1922 - lr 0.100000
2023-01-18 01:54:58,123 Evaluating as a multi-label problem: False
2023-01-18 01:54:58,140 DEV : loss 0.24886655807495117 - f1-score (micro avg)  0.7285
2023-01-18 01:54:58,145 BAD EPOCHS (no improvement): 1
2023-01-18 01:54:58,194 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:58,346 epoch 21 - iter 1/11 - loss 0.23983759 - samples/sec: 212.76 - lr: 0.100000
2023-01-18 01:54:58,475 epoch 21 - iter 2/11 - loss 0.18732372 - samples/sec: 250.21 - lr: 0.100000
2023-01-18 01:54:58,669 epoch 21 - iter 3/11 - loss 0.18661860 - samples/sec: 165.60 - lr: 0.100000
2023-01-18 01:54:58,808 epoch 21 - iter 4/11 - loss 0.19494148 - samples/sec: 231.70 - lr: 0.100000
2023-01-18 01:54:59,034 epoch 21 - iter 5/11 - loss 0.19298144 - samples/sec: 142.67 - lr: 0.100000
2023-01-18 01:54:59,159 epoch 21 - iter 6/11 - loss 0.19488147 - samples/sec: 258.08 - lr: 0.100000
2023-01-18 01:54:59,356 epoch 21 - iter 7/11 - loss 0.19793960 - samples/sec: 162.90 - lr: 0.100000
2023-01-18 01:54:59,491 epoch 21 - iter 8/11 - loss 0.19694892 - samples/sec: 240.53 - lr: 0.100000
2023-01-18 01:54:59,724 epoch 21 - iter 9/11 - loss 0.19443690 - samples/sec: 137.85 - lr: 0.100000
2023-01-18 01:54:59,857 epoch 21 - iter 10/11 - loss 0.19117767 - samples/sec: 242.41 - lr: 0.100000
2023-01-18 01:54:59,973 epoch 21 - iter 11/11 - loss 0.18850128 - samples/sec: 280.18 - lr: 0.100000
2023-01-18 01:54:59,974 ----------------------------------------------------------------------------------------------------
2023-01-18 01:54:59,974 EPOCH 21 done: loss 0.1885 - lr 0.100000
2023-01-18 01:55:00,817 Evaluating as a multi-label problem: False
2023-01-18 01:55:00,833 DEV : loss 0.11032537370920181 - f1-score (micro avg)  0.8206
2023-01-18 01:55:00,837 BAD EPOCHS (no improvement): 0
2023-01-18 01:55:00,839 saving best model
2023-01-18 01:55:05,843 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:05,976 epoch 22 - iter 1/11 - loss 0.14396931 - samples/sec: 244.26 - lr: 0.100000
2023-01-18 01:55:06,208 epoch 22 - iter 2/11 - loss 0.14744815 - samples/sec: 138.76 - lr: 0.100000
2023-01-18 01:55:06,404 epoch 22 - iter 3/11 - loss 0.13869433 - samples/sec: 163.70 - lr: 0.100000
2023-01-18 01:55:06,608 epoch 22 - iter 4/11 - loss 0.14370877 - samples/sec: 158.21 - lr: 0.100000
2023-01-18 01:55:06,767 epoch 22 - iter 5/11 - loss 0.15340017 - samples/sec: 202.17 - lr: 0.100000
2023-01-18 01:55:06,911 epoch 22 - iter 6/11 - loss 0.15613693 - samples/sec: 224.73 - lr: 0.100000
2023-01-18 01:55:07,040 epoch 22 - iter 7/11 - loss 0.15816931 - samples/sec: 249.60 - lr: 0.100000
2023-01-18 01:55:07,177 epoch 22 - iter 8/11 - loss 0.15762207 - samples/sec: 236.15 - lr: 0.100000
2023-01-18 01:55:07,312 epoch 22 - iter 9/11 - loss 0.15671081 - samples/sec: 238.13 - lr: 0.100000
2023-01-18 01:55:07,461 epoch 22 - iter 10/11 - loss 0.15704467 - samples/sec: 216.50 - lr: 0.100000
2023-01-18 01:55:07,576 epoch 22 - iter 11/11 - loss 0.15661079 - samples/sec: 281.44 - lr: 0.100000
2023-01-18 01:55:07,577 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:07,577 EPOCH 22 done: loss 0.1566 - lr 0.100000
2023-01-18 01:55:08,507 Evaluating as a multi-label problem: False
2023-01-18 01:55:08,523 DEV : loss 0.09175647050142288 - f1-score (micro avg)  0.8364
2023-01-18 01:55:08,528 BAD EPOCHS (no improvement): 0
2023-01-18 01:55:08,572 saving best model
2023-01-18 01:55:15,158 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:15,297 epoch 23 - iter 1/11 - loss 0.11632730 - samples/sec: 232.14 - lr: 0.100000
2023-01-18 01:55:15,523 epoch 23 - iter 2/11 - loss 0.11917343 - samples/sec: 142.61 - lr: 0.100000
2023-01-18 01:55:15,719 epoch 23 - iter 3/11 - loss 0.14209087 - samples/sec: 164.42 - lr: 0.100000
2023-01-18 01:55:15,923 epoch 23 - iter 4/11 - loss 0.15539846 - samples/sec: 157.62 - lr: 0.100000
2023-01-18 01:55:16,062 epoch 23 - iter 5/11 - loss 0.15695293 - samples/sec: 232.94 - lr: 0.100000
2023-01-18 01:55:16,213 epoch 23 - iter 6/11 - loss 0.16648872 - samples/sec: 213.67 - lr: 0.100000
2023-01-18 01:55:16,365 epoch 23 - iter 7/11 - loss 0.16046634 - samples/sec: 211.84 - lr: 0.100000
2023-01-18 01:55:16,600 epoch 23 - iter 8/11 - loss 0.16515776 - samples/sec: 136.48 - lr: 0.100000
2023-01-18 01:55:16,727 epoch 23 - iter 9/11 - loss 0.15866266 - samples/sec: 254.95 - lr: 0.100000
2023-01-18 01:55:16,885 epoch 23 - iter 10/11 - loss 0.15985075 - samples/sec: 204.12 - lr: 0.100000
2023-01-18 01:55:17,005 epoch 23 - iter 11/11 - loss 0.15560276 - samples/sec: 268.37 - lr: 0.100000
2023-01-18 01:55:17,006 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:17,007 EPOCH 23 done: loss 0.1556 - lr 0.100000
2023-01-18 01:55:17,847 Evaluating as a multi-label problem: False
2023-01-18 01:55:17,864 DEV : loss 0.11473052203655243 - f1-score (micro avg)  0.8311
2023-01-18 01:55:17,868 BAD EPOCHS (no improvement): 1
2023-01-18 01:55:17,871 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:18,029 epoch 24 - iter 1/11 - loss 0.17790828 - samples/sec: 203.08 - lr: 0.100000
2023-01-18 01:55:18,171 epoch 24 - iter 2/11 - loss 0.15994480 - samples/sec: 228.18 - lr: 0.100000
2023-01-18 01:55:18,393 epoch 24 - iter 3/11 - loss 0.14181958 - samples/sec: 144.89 - lr: 0.100000
2023-01-18 01:55:18,972 epoch 24 - iter 4/11 - loss 0.16999462 - samples/sec: 55.31 - lr: 0.100000
2023-01-18 01:55:19,171 epoch 24 - iter 5/11 - loss 0.17477746 - samples/sec: 162.41 - lr: 0.100000
2023-01-18 01:55:19,296 epoch 24 - iter 6/11 - loss 0.16823537 - samples/sec: 259.29 - lr: 0.100000
2023-01-18 01:55:19,421 epoch 24 - iter 7/11 - loss 0.16142805 - samples/sec: 257.41 - lr: 0.100000
2023-01-18 01:55:19,656 epoch 24 - iter 8/11 - loss 0.16221799 - samples/sec: 136.54 - lr: 0.100000
2023-01-18 01:55:19,791 epoch 24 - iter 9/11 - loss 0.16215378 - samples/sec: 238.57 - lr: 0.100000
2023-01-18 01:55:19,943 epoch 24 - iter 10/11 - loss 0.16225286 - samples/sec: 212.81 - lr: 0.100000
2023-01-18 01:55:20,051 epoch 24 - iter 11/11 - loss 0.16204934 - samples/sec: 297.97 - lr: 0.100000
2023-01-18 01:55:20,052 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:20,053 EPOCH 24 done: loss 0.1620 - lr 0.100000
2023-01-18 01:55:20,894 Evaluating as a multi-label problem: False
2023-01-18 01:55:20,911 DEV : loss 0.09329576790332794 - f1-score (micro avg)  0.8264
2023-01-18 01:55:20,915 BAD EPOCHS (no improvement): 2
2023-01-18 01:55:20,917 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:21,056 epoch 25 - iter 1/11 - loss 0.10018097 - samples/sec: 231.53 - lr: 0.100000
2023-01-18 01:55:21,214 epoch 25 - iter 2/11 - loss 0.12938023 - samples/sec: 203.83 - lr: 0.100000
2023-01-18 01:55:21,456 epoch 25 - iter 3/11 - loss 0.13977547 - samples/sec: 133.20 - lr: 0.100000
2023-01-18 01:55:21,607 epoch 25 - iter 4/11 - loss 0.13002058 - samples/sec: 213.61 - lr: 0.100000
2023-01-18 01:55:21,729 epoch 25 - iter 5/11 - loss 0.12344567 - samples/sec: 264.79 - lr: 0.100000
2023-01-18 01:55:21,879 epoch 25 - iter 6/11 - loss 0.12440425 - samples/sec: 215.15 - lr: 0.100000
2023-01-18 01:55:22,075 epoch 25 - iter 7/11 - loss 0.12948552 - samples/sec: 164.05 - lr: 0.100000
2023-01-18 01:55:22,217 epoch 25 - iter 8/11 - loss 0.13497411 - samples/sec: 227.33 - lr: 0.100000
2023-01-18 01:55:22,438 epoch 25 - iter 9/11 - loss 0.13752797 - samples/sec: 145.25 - lr: 0.100000
2023-01-18 01:55:22,575 epoch 25 - iter 10/11 - loss 0.14100241 - samples/sec: 236.06 - lr: 0.100000
2023-01-18 01:55:22,683 epoch 25 - iter 11/11 - loss 0.14091499 - samples/sec: 299.62 - lr: 0.100000
2023-01-18 01:55:22,684 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:22,685 EPOCH 25 done: loss 0.1409 - lr 0.100000
2023-01-18 01:55:23,523 Evaluating as a multi-label problem: False
2023-01-18 01:55:23,539 DEV : loss 0.11621783673763275 - f1-score (micro avg)  0.8136
2023-01-18 01:55:23,544 BAD EPOCHS (no improvement): 3
2023-01-18 01:55:23,545 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:23,784 epoch 26 - iter 1/11 - loss 0.19103445 - samples/sec: 134.83 - lr: 0.100000
2023-01-18 01:55:23,922 epoch 26 - iter 2/11 - loss 0.14648795 - samples/sec: 232.78 - lr: 0.100000
2023-01-18 01:55:24,125 epoch 26 - iter 3/11 - loss 0.13940856 - samples/sec: 158.99 - lr: 0.100000
2023-01-18 01:55:24,276 epoch 26 - iter 4/11 - loss 0.13117982 - samples/sec: 212.84 - lr: 0.100000
2023-01-18 01:55:24,433 epoch 26 - iter 5/11 - loss 0.12889866 - samples/sec: 205.49 - lr: 0.100000
2023-01-18 01:55:24,575 epoch 26 - iter 6/11 - loss 0.12658323 - samples/sec: 226.71 - lr: 0.100000
2023-01-18 01:55:24,796 epoch 26 - iter 7/11 - loss 0.12802911 - samples/sec: 145.63 - lr: 0.100000
2023-01-18 01:55:24,923 epoch 26 - iter 8/11 - loss 0.12862908 - samples/sec: 253.78 - lr: 0.100000
2023-01-18 01:55:25,075 epoch 26 - iter 9/11 - loss 0.12708138 - samples/sec: 212.97 - lr: 0.100000
2023-01-18 01:55:25,203 epoch 26 - iter 10/11 - loss 0.13080725 - samples/sec: 252.15 - lr: 0.100000
2023-01-18 01:55:25,304 epoch 26 - iter 11/11 - loss 0.13071727 - samples/sec: 318.80 - lr: 0.100000
2023-01-18 01:55:25,305 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:25,306 EPOCH 26 done: loss 0.1307 - lr 0.100000
2023-01-18 01:55:26,141 Evaluating as a multi-label problem: False
2023-01-18 01:55:26,157 DEV : loss 0.0981341153383255 - f1-score (micro avg)  0.8453
2023-01-18 01:55:26,162 BAD EPOCHS (no improvement): 0
2023-01-18 01:55:26,164 saving best model
2023-01-18 01:55:31,184 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:31,322 epoch 27 - iter 1/11 - loss 0.14268358 - samples/sec: 235.29 - lr: 0.100000
2023-01-18 01:55:31,527 epoch 27 - iter 2/11 - loss 0.12252047 - samples/sec: 156.88 - lr: 0.100000
2023-01-18 01:55:31,772 epoch 27 - iter 3/11 - loss 0.12993294 - samples/sec: 131.27 - lr: 0.100000
2023-01-18 01:55:31,919 epoch 27 - iter 4/11 - loss 0.12581927 - samples/sec: 219.36 - lr: 0.100000
2023-01-18 01:55:32,051 epoch 27 - iter 5/11 - loss 0.12418058 - samples/sec: 244.80 - lr: 0.100000
2023-01-18 01:55:32,253 epoch 27 - iter 6/11 - loss 0.13407260 - samples/sec: 159.64 - lr: 0.100000
2023-01-18 01:55:32,397 epoch 27 - iter 7/11 - loss 0.13320447 - samples/sec: 223.98 - lr: 0.100000
2023-01-18 01:55:32,622 epoch 27 - iter 8/11 - loss 0.12957393 - samples/sec: 142.70 - lr: 0.100000
2023-01-18 01:55:32,758 epoch 27 - iter 9/11 - loss 0.13049551 - samples/sec: 236.63 - lr: 0.100000
2023-01-18 01:55:32,913 epoch 27 - iter 10/11 - loss 0.12690862 - samples/sec: 208.93 - lr: 0.100000
2023-01-18 01:55:33,046 epoch 27 - iter 11/11 - loss 0.12493352 - samples/sec: 241.53 - lr: 0.100000
2023-01-18 01:55:33,047 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:33,048 EPOCH 27 done: loss 0.1249 - lr 0.100000
2023-01-18 01:55:33,893 Evaluating as a multi-label problem: False
2023-01-18 01:55:33,909 DEV : loss 0.07481466233730316 - f1-score (micro avg)  0.8637
2023-01-18 01:55:33,914 BAD EPOCHS (no improvement): 0
2023-01-18 01:55:33,915 saving best model
2023-01-18 01:55:38,913 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:39,073 epoch 28 - iter 1/11 - loss 0.10176768 - samples/sec: 202.50 - lr: 0.100000
2023-01-18 01:55:39,214 epoch 28 - iter 2/11 - loss 0.09883339 - samples/sec: 227.73 - lr: 0.100000
2023-01-18 01:55:39,765 epoch 28 - iter 3/11 - loss 0.10687003 - samples/sec: 58.27 - lr: 0.100000
2023-01-18 01:55:39,966 epoch 28 - iter 4/11 - loss 0.11548556 - samples/sec: 159.63 - lr: 0.100000
2023-01-18 01:55:40,097 epoch 28 - iter 5/11 - loss 0.11104689 - samples/sec: 247.10 - lr: 0.100000
2023-01-18 01:55:40,296 epoch 28 - iter 6/11 - loss 0.11832254 - samples/sec: 161.78 - lr: 0.100000
2023-01-18 01:55:40,449 epoch 28 - iter 7/11 - loss 0.11805981 - samples/sec: 210.11 - lr: 0.100000
2023-01-18 01:55:40,587 epoch 28 - iter 8/11 - loss 0.11582335 - samples/sec: 234.76 - lr: 0.100000
2023-01-18 01:55:40,717 epoch 28 - iter 9/11 - loss 0.11365718 - samples/sec: 247.77 - lr: 0.100000
2023-01-18 01:55:40,851 epoch 28 - iter 10/11 - loss 0.11562167 - samples/sec: 240.95 - lr: 0.100000
2023-01-18 01:55:41,042 epoch 28 - iter 11/11 - loss 0.11587415 - samples/sec: 168.82 - lr: 0.100000
2023-01-18 01:55:41,043 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:41,044 EPOCH 28 done: loss 0.1159 - lr 0.100000
2023-01-18 01:55:41,894 Evaluating as a multi-label problem: False
2023-01-18 01:55:41,911 DEV : loss 0.08398745208978653 - f1-score (micro avg)  0.8549
2023-01-18 01:55:41,915 BAD EPOCHS (no improvement): 1
2023-01-18 01:55:41,917 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:42,069 epoch 29 - iter 1/11 - loss 0.05877917 - samples/sec: 211.59 - lr: 0.100000
2023-01-18 01:55:42,212 epoch 29 - iter 2/11 - loss 0.08442657 - samples/sec: 225.30 - lr: 0.100000
2023-01-18 01:55:42,411 epoch 29 - iter 3/11 - loss 0.11859416 - samples/sec: 162.14 - lr: 0.100000
2023-01-18 01:55:42,609 epoch 29 - iter 4/11 - loss 0.11708899 - samples/sec: 161.93 - lr: 0.100000
2023-01-18 01:55:42,750 epoch 29 - iter 5/11 - loss 0.11542094 - samples/sec: 229.00 - lr: 0.100000
2023-01-18 01:55:42,885 epoch 29 - iter 6/11 - loss 0.12394953 - samples/sec: 238.86 - lr: 0.100000
2023-01-18 01:55:43,016 epoch 29 - iter 7/11 - loss 0.12556914 - samples/sec: 247.03 - lr: 0.100000
2023-01-18 01:55:43,159 epoch 29 - iter 8/11 - loss 0.12032976 - samples/sec: 225.60 - lr: 0.100000
2023-01-18 01:55:43,279 epoch 29 - iter 9/11 - loss 0.11665618 - samples/sec: 268.43 - lr: 0.100000
2023-01-18 01:55:43,516 epoch 29 - iter 10/11 - loss 0.11629663 - samples/sec: 135.17 - lr: 0.100000
2023-01-18 01:55:43,710 epoch 29 - iter 11/11 - loss 0.11321543 - samples/sec: 166.00 - lr: 0.100000
2023-01-18 01:55:43,711 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:43,712 EPOCH 29 done: loss 0.1132 - lr 0.100000
2023-01-18 01:55:44,562 Evaluating as a multi-label problem: False
2023-01-18 01:55:44,578 DEV : loss 0.08210823684930801 - f1-score (micro avg)  0.8419
2023-01-18 01:55:44,584 BAD EPOCHS (no improvement): 2
2023-01-18 01:55:44,585 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:44,736 epoch 30 - iter 1/11 - loss 0.10756352 - samples/sec: 214.31 - lr: 0.100000
2023-01-18 01:55:44,874 epoch 30 - iter 2/11 - loss 0.09857599 - samples/sec: 233.05 - lr: 0.100000
2023-01-18 01:55:45,016 epoch 30 - iter 3/11 - loss 0.10086985 - samples/sec: 227.63 - lr: 0.100000
2023-01-18 01:55:45,213 epoch 30 - iter 4/11 - loss 0.10617343 - samples/sec: 163.74 - lr: 0.100000
2023-01-18 01:55:45,438 epoch 30 - iter 5/11 - loss 0.10341159 - samples/sec: 142.90 - lr: 0.100000
2023-01-18 01:55:45,677 epoch 30 - iter 6/11 - loss 0.10525478 - samples/sec: 134.52 - lr: 0.100000
2023-01-18 01:55:45,820 epoch 30 - iter 7/11 - loss 0.10362058 - samples/sec: 226.17 - lr: 0.100000
2023-01-18 01:55:45,952 epoch 30 - iter 8/11 - loss 0.10558693 - samples/sec: 243.59 - lr: 0.100000
2023-01-18 01:55:46,091 epoch 30 - iter 9/11 - loss 0.11199140 - samples/sec: 232.02 - lr: 0.100000
2023-01-18 01:55:46,250 epoch 30 - iter 10/11 - loss 0.11870094 - samples/sec: 203.19 - lr: 0.100000
2023-01-18 01:55:46,383 epoch 30 - iter 11/11 - loss 0.11794639 - samples/sec: 242.41 - lr: 0.100000
2023-01-18 01:55:46,384 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:46,385 EPOCH 30 done: loss 0.1179 - lr 0.100000
2023-01-18 01:55:47,236 Evaluating as a multi-label problem: False
2023-01-18 01:55:47,255 DEV : loss 0.09646914154291153 - f1-score (micro avg)  0.8374
2023-01-18 01:55:47,261 BAD EPOCHS (no improvement): 3
2023-01-18 01:55:47,262 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:47,434 epoch 31 - iter 1/11 - loss 0.09116462 - samples/sec: 187.37 - lr: 0.100000
2023-01-18 01:55:47,619 epoch 31 - iter 2/11 - loss 0.08702533 - samples/sec: 173.76 - lr: 0.100000
2023-01-18 01:55:47,859 epoch 31 - iter 3/11 - loss 0.08944663 - samples/sec: 134.00 - lr: 0.100000
2023-01-18 01:55:48,019 epoch 31 - iter 4/11 - loss 0.09679409 - samples/sec: 202.33 - lr: 0.100000
2023-01-18 01:55:48,311 epoch 31 - iter 5/11 - loss 0.09479800 - samples/sec: 110.03 - lr: 0.100000
2023-01-18 01:55:48,503 epoch 31 - iter 6/11 - loss 0.09866534 - samples/sec: 167.53 - lr: 0.100000
2023-01-18 01:55:48,687 epoch 31 - iter 7/11 - loss 0.10299442 - samples/sec: 175.21 - lr: 0.100000
2023-01-18 01:55:48,956 epoch 31 - iter 8/11 - loss 0.10316001 - samples/sec: 119.47 - lr: 0.100000
2023-01-18 01:55:49,114 epoch 31 - iter 9/11 - loss 0.10591979 - samples/sec: 204.23 - lr: 0.100000
2023-01-18 01:55:49,287 epoch 31 - iter 10/11 - loss 0.10299246 - samples/sec: 186.02 - lr: 0.100000
2023-01-18 01:55:49,438 epoch 31 - iter 11/11 - loss 0.10679870 - samples/sec: 213.22 - lr: 0.100000
2023-01-18 01:55:49,439 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:49,440 EPOCH 31 done: loss 0.1068 - lr 0.100000
2023-01-18 01:55:50,551 Evaluating as a multi-label problem: False
2023-01-18 01:55:50,569 DEV : loss 0.07735083997249603 - f1-score (micro avg)  0.8473
2023-01-18 01:55:50,575 Epoch    31: reducing learning rate of group 0 to 5.0000e-02.
2023-01-18 01:55:50,575 BAD EPOCHS (no improvement): 4
2023-01-18 01:55:50,577 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:50,773 epoch 32 - iter 1/11 - loss 0.09246346 - samples/sec: 164.28 - lr: 0.050000
2023-01-18 01:55:51,060 epoch 32 - iter 2/11 - loss 0.09569631 - samples/sec: 112.26 - lr: 0.050000
2023-01-18 01:55:51,234 epoch 32 - iter 3/11 - loss 0.09357704 - samples/sec: 184.96 - lr: 0.050000
2023-01-18 01:55:51,479 epoch 32 - iter 4/11 - loss 0.09703280 - samples/sec: 131.15 - lr: 0.050000
2023-01-18 01:55:52,039 epoch 32 - iter 5/11 - loss 0.09588464 - samples/sec: 57.27 - lr: 0.050000
2023-01-18 01:55:52,191 epoch 32 - iter 6/11 - loss 0.09726377 - samples/sec: 212.22 - lr: 0.050000
2023-01-18 01:55:52,351 epoch 32 - iter 7/11 - loss 0.09742590 - samples/sec: 202.08 - lr: 0.050000
2023-01-18 01:55:52,591 epoch 32 - iter 8/11 - loss 0.10096453 - samples/sec: 134.01 - lr: 0.050000
2023-01-18 01:55:52,773 epoch 32 - iter 9/11 - loss 0.09854616 - samples/sec: 176.51 - lr: 0.050000
2023-01-18 01:55:52,941 epoch 32 - iter 10/11 - loss 0.09435616 - samples/sec: 191.53 - lr: 0.050000
2023-01-18 01:55:53,065 epoch 32 - iter 11/11 - loss 0.09392332 - samples/sec: 262.33 - lr: 0.050000
2023-01-18 01:55:53,066 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:53,066 EPOCH 32 done: loss 0.0939 - lr 0.050000
2023-01-18 01:55:54,174 Evaluating as a multi-label problem: False
2023-01-18 01:55:54,191 DEV : loss 0.06664195656776428 - f1-score (micro avg)  0.878
2023-01-18 01:55:54,197 BAD EPOCHS (no improvement): 0
2023-01-18 01:55:54,199 saving best model
2023-01-18 01:55:59,322 ----------------------------------------------------------------------------------------------------
2023-01-18 01:55:59,494 epoch 33 - iter 1/11 - loss 0.04828023 - samples/sec: 187.33 - lr: 0.050000
2023-01-18 01:55:59,652 epoch 33 - iter 2/11 - loss 0.06685544 - samples/sec: 203.87 - lr: 0.050000
2023-01-18 01:55:59,900 epoch 33 - iter 3/11 - loss 0.08276534 - samples/sec: 129.52 - lr: 0.050000
2023-01-18 01:56:00,073 epoch 33 - iter 4/11 - loss 0.08620597 - samples/sec: 187.05 - lr: 0.050000
2023-01-18 01:56:00,235 epoch 33 - iter 5/11 - loss 0.08709251 - samples/sec: 198.76 - lr: 0.050000
2023-01-18 01:56:00,423 epoch 33 - iter 6/11 - loss 0.08669642 - samples/sec: 170.70 - lr: 0.050000
2023-01-18 01:56:00,593 epoch 33 - iter 7/11 - loss 0.08927396 - samples/sec: 190.01 - lr: 0.050000
2023-01-18 01:56:00,864 epoch 33 - iter 8/11 - loss 0.09026762 - samples/sec: 118.58 - lr: 0.050000
2023-01-18 01:56:01,018 epoch 33 - iter 9/11 - loss 0.08602395 - samples/sec: 209.67 - lr: 0.050000
2023-01-18 01:56:01,307 epoch 33 - iter 10/11 - loss 0.08524082 - samples/sec: 111.01 - lr: 0.050000
2023-01-18 01:56:01,453 epoch 33 - iter 11/11 - loss 0.08455558 - samples/sec: 221.85 - lr: 0.050000
2023-01-18 01:56:01,454 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:01,454 EPOCH 33 done: loss 0.0846 - lr 0.050000
2023-01-18 01:56:02,562 Evaluating as a multi-label problem: False
2023-01-18 01:56:02,579 DEV : loss 0.06127021089196205 - f1-score (micro avg)  0.8737
2023-01-18 01:56:02,585 BAD EPOCHS (no improvement): 1
2023-01-18 01:56:02,586 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:02,862 epoch 34 - iter 1/11 - loss 0.14129130 - samples/sec: 116.59 - lr: 0.050000
2023-01-18 01:56:03,101 epoch 34 - iter 2/11 - loss 0.10867215 - samples/sec: 134.24 - lr: 0.050000
2023-01-18 01:56:03,279 epoch 34 - iter 3/11 - loss 0.10103422 - samples/sec: 181.15 - lr: 0.050000
2023-01-18 01:56:03,445 epoch 34 - iter 4/11 - loss 0.09740892 - samples/sec: 194.68 - lr: 0.050000
2023-01-18 01:56:03,627 epoch 34 - iter 5/11 - loss 0.09540475 - samples/sec: 176.15 - lr: 0.050000
2023-01-18 01:56:03,917 epoch 34 - iter 6/11 - loss 0.09668472 - samples/sec: 111.01 - lr: 0.050000
2023-01-18 01:56:04,085 epoch 34 - iter 7/11 - loss 0.09220075 - samples/sec: 191.27 - lr: 0.050000
2023-01-18 01:56:04,325 epoch 34 - iter 8/11 - loss 0.09200332 - samples/sec: 134.39 - lr: 0.050000
2023-01-18 01:56:04,475 epoch 34 - iter 9/11 - loss 0.09144031 - samples/sec: 214.34 - lr: 0.050000
2023-01-18 01:56:04,667 epoch 34 - iter 10/11 - loss 0.08960090 - samples/sec: 167.86 - lr: 0.050000
2023-01-18 01:56:04,811 epoch 34 - iter 11/11 - loss 0.08729896 - samples/sec: 222.84 - lr: 0.050000
2023-01-18 01:56:04,812 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:04,813 EPOCH 34 done: loss 0.0873 - lr 0.050000
2023-01-18 01:56:05,920 Evaluating as a multi-label problem: False
2023-01-18 01:56:05,937 DEV : loss 0.055130504071712494 - f1-score (micro avg)  0.8642
2023-01-18 01:56:05,943 BAD EPOCHS (no improvement): 2
2023-01-18 01:56:05,945 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:06,188 epoch 35 - iter 1/11 - loss 0.07083254 - samples/sec: 132.15 - lr: 0.050000
2023-01-18 01:56:06,487 epoch 35 - iter 2/11 - loss 0.08819061 - samples/sec: 107.39 - lr: 0.050000
2023-01-18 01:56:06,644 epoch 35 - iter 3/11 - loss 0.08347374 - samples/sec: 206.49 - lr: 0.050000
2023-01-18 01:56:06,812 epoch 35 - iter 4/11 - loss 0.07867802 - samples/sec: 191.55 - lr: 0.050000
2023-01-18 01:56:06,983 epoch 35 - iter 5/11 - loss 0.08521349 - samples/sec: 188.37 - lr: 0.050000
2023-01-18 01:56:07,255 epoch 35 - iter 6/11 - loss 0.08370829 - samples/sec: 118.15 - lr: 0.050000
2023-01-18 01:56:07,497 epoch 35 - iter 7/11 - loss 0.08431090 - samples/sec: 132.50 - lr: 0.050000
2023-01-18 01:56:07,666 epoch 35 - iter 8/11 - loss 0.08892424 - samples/sec: 191.33 - lr: 0.050000
2023-01-18 01:56:07,845 epoch 35 - iter 9/11 - loss 0.08662672 - samples/sec: 179.18 - lr: 0.050000
2023-01-18 01:56:08,036 epoch 35 - iter 10/11 - loss 0.08562732 - samples/sec: 168.90 - lr: 0.050000
2023-01-18 01:56:08,191 epoch 35 - iter 11/11 - loss 0.08734139 - samples/sec: 208.28 - lr: 0.050000
2023-01-18 01:56:08,192 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:08,192 EPOCH 35 done: loss 0.0873 - lr 0.050000
2023-01-18 01:56:09,300 Evaluating as a multi-label problem: False
2023-01-18 01:56:09,318 DEV : loss 0.04977085441350937 - f1-score (micro avg)  0.8848
2023-01-18 01:56:09,324 BAD EPOCHS (no improvement): 0
2023-01-18 01:56:09,325 saving best model
2023-01-18 01:56:14,326 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:14,619 epoch 36 - iter 1/11 - loss 0.08163755 - samples/sec: 110.05 - lr: 0.050000
2023-01-18 01:56:15,164 epoch 36 - iter 2/11 - loss 0.07294597 - samples/sec: 58.79 - lr: 0.050000
2023-01-18 01:56:15,336 epoch 36 - iter 3/11 - loss 0.06788056 - samples/sec: 187.92 - lr: 0.050000
2023-01-18 01:56:15,505 epoch 36 - iter 4/11 - loss 0.06854845 - samples/sec: 190.15 - lr: 0.050000
2023-01-18 01:56:15,748 epoch 36 - iter 5/11 - loss 0.07207929 - samples/sec: 132.71 - lr: 0.050000
2023-01-18 01:56:15,911 epoch 36 - iter 6/11 - loss 0.07319905 - samples/sec: 197.12 - lr: 0.050000
2023-01-18 01:56:16,098 epoch 36 - iter 7/11 - loss 0.07587052 - samples/sec: 172.09 - lr: 0.050000
2023-01-18 01:56:16,258 epoch 36 - iter 8/11 - loss 0.07925862 - samples/sec: 201.75 - lr: 0.050000
2023-01-18 01:56:16,552 epoch 36 - iter 9/11 - loss 0.08062906 - samples/sec: 109.21 - lr: 0.050000
2023-01-18 01:56:16,738 epoch 36 - iter 10/11 - loss 0.07927840 - samples/sec: 172.81 - lr: 0.050000
2023-01-18 01:56:16,900 epoch 36 - iter 11/11 - loss 0.08130515 - samples/sec: 199.06 - lr: 0.050000
2023-01-18 01:56:16,901 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:16,902 EPOCH 36 done: loss 0.0813 - lr 0.050000
2023-01-18 01:56:18,156 Evaluating as a multi-label problem: False
2023-01-18 01:56:18,174 DEV : loss 0.05786823108792305 - f1-score (micro avg)  0.8855
2023-01-18 01:56:18,180 BAD EPOCHS (no improvement): 0
2023-01-18 01:56:18,262 saving best model
2023-01-18 01:56:23,632 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:23,804 epoch 37 - iter 1/11 - loss 0.04627994 - samples/sec: 188.18 - lr: 0.050000
2023-01-18 01:56:24,055 epoch 37 - iter 2/11 - loss 0.07470989 - samples/sec: 128.26 - lr: 0.050000
2023-01-18 01:56:24,219 epoch 37 - iter 3/11 - loss 0.07042039 - samples/sec: 195.96 - lr: 0.050000
2023-01-18 01:56:24,389 epoch 37 - iter 4/11 - loss 0.07359947 - samples/sec: 189.65 - lr: 0.050000
2023-01-18 01:56:24,560 epoch 37 - iter 5/11 - loss 0.07385124 - samples/sec: 188.24 - lr: 0.050000
2023-01-18 01:56:24,835 epoch 37 - iter 6/11 - loss 0.07105786 - samples/sec: 116.95 - lr: 0.050000
2023-01-18 01:56:25,024 epoch 37 - iter 7/11 - loss 0.07344228 - samples/sec: 170.52 - lr: 0.050000
2023-01-18 01:56:25,221 epoch 37 - iter 8/11 - loss 0.07216334 - samples/sec: 163.59 - lr: 0.050000
2023-01-18 01:56:25,396 epoch 37 - iter 9/11 - loss 0.07183380 - samples/sec: 183.66 - lr: 0.050000
2023-01-18 01:56:25,582 epoch 37 - iter 10/11 - loss 0.07230041 - samples/sec: 172.66 - lr: 0.050000
2023-01-18 01:56:25,831 epoch 37 - iter 11/11 - loss 0.07157677 - samples/sec: 129.32 - lr: 0.050000
2023-01-18 01:56:25,833 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:25,833 EPOCH 37 done: loss 0.0716 - lr 0.050000
2023-01-18 01:56:26,956 Evaluating as a multi-label problem: False
2023-01-18 01:56:26,975 DEV : loss 0.0539773553609848 - f1-score (micro avg)  0.871
2023-01-18 01:56:26,981 BAD EPOCHS (no improvement): 1
2023-01-18 01:56:26,983 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:27,264 epoch 38 - iter 1/11 - loss 0.08186579 - samples/sec: 114.19 - lr: 0.050000
2023-01-18 01:56:27,453 epoch 38 - iter 2/11 - loss 0.08370229 - samples/sec: 170.77 - lr: 0.050000
2023-01-18 01:56:27,640 epoch 38 - iter 3/11 - loss 0.07494468 - samples/sec: 171.78 - lr: 0.050000
2023-01-18 01:56:27,804 epoch 38 - iter 4/11 - loss 0.07226400 - samples/sec: 196.70 - lr: 0.050000
2023-01-18 01:56:27,978 epoch 38 - iter 5/11 - loss 0.08055923 - samples/sec: 184.48 - lr: 0.050000
2023-01-18 01:56:28,275 epoch 38 - iter 6/11 - loss 0.08056482 - samples/sec: 108.03 - lr: 0.050000
2023-01-18 01:56:28,450 epoch 38 - iter 7/11 - loss 0.07855062 - samples/sec: 184.30 - lr: 0.050000
2023-01-18 01:56:28,696 epoch 38 - iter 8/11 - loss 0.07906822 - samples/sec: 131.25 - lr: 0.050000
2023-01-18 01:56:28,890 epoch 38 - iter 9/11 - loss 0.08282671 - samples/sec: 165.19 - lr: 0.050000
2023-01-18 01:56:29,135 epoch 38 - iter 10/11 - loss 0.08282306 - samples/sec: 131.43 - lr: 0.050000
2023-01-18 01:56:29,264 epoch 38 - iter 11/11 - loss 0.08222020 - samples/sec: 251.11 - lr: 0.050000
2023-01-18 01:56:29,265 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:29,265 EPOCH 38 done: loss 0.0822 - lr 0.050000
2023-01-18 01:56:30,384 Evaluating as a multi-label problem: False
2023-01-18 01:56:30,401 DEV : loss 0.05950168892741203 - f1-score (micro avg)  0.8749
2023-01-18 01:56:30,407 BAD EPOCHS (no improvement): 2
2023-01-18 01:56:30,408 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:30,607 epoch 39 - iter 1/11 - loss 0.09284581 - samples/sec: 162.26 - lr: 0.050000
2023-01-18 01:56:30,794 epoch 39 - iter 2/11 - loss 0.10326016 - samples/sec: 171.64 - lr: 0.050000
2023-01-18 01:56:30,962 epoch 39 - iter 3/11 - loss 0.11094055 - samples/sec: 191.42 - lr: 0.050000
2023-01-18 01:56:31,239 epoch 39 - iter 4/11 - loss 0.10046543 - samples/sec: 116.26 - lr: 0.050000
2023-01-18 01:56:31,427 epoch 39 - iter 5/11 - loss 0.09390159 - samples/sec: 171.16 - lr: 0.050000
2023-01-18 01:56:31,602 epoch 39 - iter 6/11 - loss 0.09020480 - samples/sec: 184.04 - lr: 0.050000
2023-01-18 01:56:31,844 epoch 39 - iter 7/11 - loss 0.08674379 - samples/sec: 132.53 - lr: 0.050000
2023-01-18 01:56:32,019 epoch 39 - iter 8/11 - loss 0.08418197 - samples/sec: 184.31 - lr: 0.050000
2023-01-18 01:56:32,316 epoch 39 - iter 9/11 - loss 0.08203929 - samples/sec: 108.26 - lr: 0.050000
2023-01-18 01:56:32,487 epoch 39 - iter 10/11 - loss 0.08039712 - samples/sec: 187.74 - lr: 0.050000
2023-01-18 01:56:32,628 epoch 39 - iter 11/11 - loss 0.07948357 - samples/sec: 228.50 - lr: 0.050000
2023-01-18 01:56:32,629 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:32,630 EPOCH 39 done: loss 0.0795 - lr 0.050000
2023-01-18 01:56:33,739 Evaluating as a multi-label problem: False
2023-01-18 01:56:33,757 DEV : loss 0.06090981140732765 - f1-score (micro avg)  0.8764
2023-01-18 01:56:33,762 BAD EPOCHS (no improvement): 3
2023-01-18 01:56:33,764 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:33,939 epoch 40 - iter 1/11 - loss 0.05976102 - samples/sec: 184.20 - lr: 0.050000
2023-01-18 01:56:34,124 epoch 40 - iter 2/11 - loss 0.05584189 - samples/sec: 173.81 - lr: 0.050000
2023-01-18 01:56:34,366 epoch 40 - iter 3/11 - loss 0.06600838 - samples/sec: 132.96 - lr: 0.050000
2023-01-18 01:56:34,528 epoch 40 - iter 4/11 - loss 0.06455251 - samples/sec: 199.33 - lr: 0.050000
2023-01-18 01:56:35,178 epoch 40 - iter 5/11 - loss 0.06605367 - samples/sec: 49.31 - lr: 0.050000
2023-01-18 01:56:35,346 epoch 40 - iter 6/11 - loss 0.07121041 - samples/sec: 192.06 - lr: 0.050000
2023-01-18 01:56:35,514 epoch 40 - iter 7/11 - loss 0.07525636 - samples/sec: 191.56 - lr: 0.050000
2023-01-18 01:56:35,697 epoch 40 - iter 8/11 - loss 0.07315001 - samples/sec: 175.81 - lr: 0.050000
2023-01-18 01:56:35,890 epoch 40 - iter 9/11 - loss 0.07442973 - samples/sec: 167.04 - lr: 0.050000
2023-01-18 01:56:36,061 epoch 40 - iter 10/11 - loss 0.07339160 - samples/sec: 188.68 - lr: 0.050000
2023-01-18 01:56:36,310 epoch 40 - iter 11/11 - loss 0.07229186 - samples/sec: 129.18 - lr: 0.050000
2023-01-18 01:56:36,311 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:36,311 EPOCH 40 done: loss 0.0723 - lr 0.050000
2023-01-18 01:56:37,422 Evaluating as a multi-label problem: False
2023-01-18 01:56:37,440 DEV : loss 0.052394766360521317 - f1-score (micro avg)  0.8733
2023-01-18 01:56:37,445 Epoch    40: reducing learning rate of group 0 to 2.5000e-02.
2023-01-18 01:56:37,446 BAD EPOCHS (no improvement): 4
2023-01-18 01:56:37,448 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:37,725 epoch 41 - iter 1/11 - loss 0.10626907 - samples/sec: 115.73 - lr: 0.025000
2023-01-18 01:56:37,967 epoch 41 - iter 2/11 - loss 0.09971234 - samples/sec: 132.79 - lr: 0.025000
2023-01-18 01:56:38,215 epoch 41 - iter 3/11 - loss 0.08299293 - samples/sec: 129.65 - lr: 0.025000
2023-01-18 01:56:38,381 epoch 41 - iter 4/11 - loss 0.07924780 - samples/sec: 194.69 - lr: 0.025000
2023-01-18 01:56:38,671 epoch 41 - iter 5/11 - loss 0.07719442 - samples/sec: 110.66 - lr: 0.025000
2023-01-18 01:56:38,839 epoch 41 - iter 6/11 - loss 0.07474091 - samples/sec: 192.17 - lr: 0.025000
2023-01-18 01:56:39,012 epoch 41 - iter 7/11 - loss 0.07266149 - samples/sec: 185.97 - lr: 0.025000
2023-01-18 01:56:39,179 epoch 41 - iter 8/11 - loss 0.07115313 - samples/sec: 192.43 - lr: 0.025000
2023-01-18 01:56:39,352 epoch 41 - iter 9/11 - loss 0.06920513 - samples/sec: 186.19 - lr: 0.025000
2023-01-18 01:56:39,512 epoch 41 - iter 10/11 - loss 0.06739511 - samples/sec: 201.57 - lr: 0.025000
2023-01-18 01:56:39,641 epoch 41 - iter 11/11 - loss 0.06659078 - samples/sec: 250.11 - lr: 0.025000
2023-01-18 01:56:39,642 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:39,643 EPOCH 41 done: loss 0.0666 - lr 0.025000
2023-01-18 01:56:40,749 Evaluating as a multi-label problem: False
2023-01-18 01:56:40,767 DEV : loss 0.054214879870414734 - f1-score (micro avg)  0.8665
2023-01-18 01:56:40,773 BAD EPOCHS (no improvement): 1
2023-01-18 01:56:40,774 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:41,068 epoch 42 - iter 1/11 - loss 0.08988079 - samples/sec: 109.55 - lr: 0.025000
2023-01-18 01:56:41,238 epoch 42 - iter 2/11 - loss 0.07677992 - samples/sec: 189.03 - lr: 0.025000
2023-01-18 01:56:41,422 epoch 42 - iter 3/11 - loss 0.07545505 - samples/sec: 174.78 - lr: 0.025000
2023-01-18 01:56:41,696 epoch 42 - iter 4/11 - loss 0.06890144 - samples/sec: 117.31 - lr: 0.025000
2023-01-18 01:56:41,869 epoch 42 - iter 5/11 - loss 0.06678582 - samples/sec: 186.87 - lr: 0.025000
2023-01-18 01:56:42,055 epoch 42 - iter 6/11 - loss 0.06940558 - samples/sec: 173.26 - lr: 0.025000
2023-01-18 01:56:42,224 epoch 42 - iter 7/11 - loss 0.06813951 - samples/sec: 190.40 - lr: 0.025000
2023-01-18 01:56:42,464 epoch 42 - iter 8/11 - loss 0.06796364 - samples/sec: 133.67 - lr: 0.025000
2023-01-18 01:56:42,706 epoch 42 - iter 9/11 - loss 0.06729756 - samples/sec: 132.71 - lr: 0.025000
2023-01-18 01:56:42,880 epoch 42 - iter 10/11 - loss 0.06455236 - samples/sec: 185.98 - lr: 0.025000
2023-01-18 01:56:43,024 epoch 42 - iter 11/11 - loss 0.06356614 - samples/sec: 224.36 - lr: 0.025000
2023-01-18 01:56:43,024 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:43,025 EPOCH 42 done: loss 0.0636 - lr 0.025000
2023-01-18 01:56:44,140 Evaluating as a multi-label problem: False
2023-01-18 01:56:44,157 DEV : loss 0.05775168538093567 - f1-score (micro avg)  0.876
2023-01-18 01:56:44,163 BAD EPOCHS (no improvement): 2
2023-01-18 01:56:44,165 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:44,352 epoch 43 - iter 1/11 - loss 0.06249786 - samples/sec: 171.64 - lr: 0.025000
2023-01-18 01:56:44,635 epoch 43 - iter 2/11 - loss 0.05812506 - samples/sec: 113.44 - lr: 0.025000
2023-01-18 01:56:44,804 epoch 43 - iter 3/11 - loss 0.06178621 - samples/sec: 191.37 - lr: 0.025000
2023-01-18 01:56:45,045 epoch 43 - iter 4/11 - loss 0.06232288 - samples/sec: 133.32 - lr: 0.025000
2023-01-18 01:56:45,220 epoch 43 - iter 5/11 - loss 0.06850014 - samples/sec: 183.98 - lr: 0.025000
2023-01-18 01:56:45,387 epoch 43 - iter 6/11 - loss 0.06673594 - samples/sec: 193.34 - lr: 0.025000
2023-01-18 01:56:45,548 epoch 43 - iter 7/11 - loss 0.06184537 - samples/sec: 199.38 - lr: 0.025000
2023-01-18 01:56:45,740 epoch 43 - iter 8/11 - loss 0.06431115 - samples/sec: 167.81 - lr: 0.025000
2023-01-18 01:56:46,030 epoch 43 - iter 9/11 - loss 0.06769781 - samples/sec: 110.79 - lr: 0.025000
2023-01-18 01:56:46,204 epoch 43 - iter 10/11 - loss 0.06488940 - samples/sec: 184.58 - lr: 0.025000
2023-01-18 01:56:46,358 epoch 43 - iter 11/11 - loss 0.06528378 - samples/sec: 210.58 - lr: 0.025000
2023-01-18 01:56:46,359 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:46,359 EPOCH 43 done: loss 0.0653 - lr 0.025000
2023-01-18 01:56:47,473 Evaluating as a multi-label problem: False
2023-01-18 01:56:47,490 DEV : loss 0.049832358956336975 - f1-score (micro avg)  0.8759
2023-01-18 01:56:47,496 BAD EPOCHS (no improvement): 3
2023-01-18 01:56:47,498 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:47,694 epoch 44 - iter 1/11 - loss 0.05907865 - samples/sec: 163.50 - lr: 0.025000
2023-01-18 01:56:47,877 epoch 44 - iter 2/11 - loss 0.07484094 - samples/sec: 176.07 - lr: 0.025000
2023-01-18 01:56:48,334 epoch 44 - iter 3/11 - loss 0.07469979 - samples/sec: 70.25 - lr: 0.025000
2023-01-18 01:56:48,505 epoch 44 - iter 4/11 - loss 0.06741799 - samples/sec: 188.67 - lr: 0.025000
2023-01-18 01:56:48,664 epoch 44 - iter 5/11 - loss 0.06515776 - samples/sec: 203.10 - lr: 0.025000
2023-01-18 01:56:48,827 epoch 44 - iter 6/11 - loss 0.06210334 - samples/sec: 197.46 - lr: 0.025000
2023-01-18 01:56:49,114 epoch 44 - iter 7/11 - loss 0.06334550 - samples/sec: 111.68 - lr: 0.025000
2023-01-18 01:56:49,282 epoch 44 - iter 8/11 - loss 0.06534716 - samples/sec: 191.76 - lr: 0.025000
2023-01-18 01:56:49,467 epoch 44 - iter 9/11 - loss 0.06350199 - samples/sec: 173.68 - lr: 0.025000
2023-01-18 01:56:49,707 epoch 44 - iter 10/11 - loss 0.06369745 - samples/sec: 133.85 - lr: 0.025000
2023-01-18 01:56:49,937 epoch 44 - iter 11/11 - loss 0.06337663 - samples/sec: 139.89 - lr: 0.025000
2023-01-18 01:56:49,938 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:49,939 EPOCH 44 done: loss 0.0634 - lr 0.025000
2023-01-18 01:56:51,054 Evaluating as a multi-label problem: False
2023-01-18 01:56:51,071 DEV : loss 0.051211606711149216 - f1-score (micro avg)  0.8734
2023-01-18 01:56:51,077 Epoch    44: reducing learning rate of group 0 to 1.2500e-02.
2023-01-18 01:56:51,077 BAD EPOCHS (no improvement): 4
2023-01-18 01:56:51,079 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:51,287 epoch 45 - iter 1/11 - loss 0.05574047 - samples/sec: 155.04 - lr: 0.012500
2023-01-18 01:56:51,444 epoch 45 - iter 2/11 - loss 0.07617132 - samples/sec: 205.48 - lr: 0.012500
2023-01-18 01:56:51,689 epoch 45 - iter 3/11 - loss 0.07844365 - samples/sec: 130.85 - lr: 0.012500
2023-01-18 01:56:51,846 epoch 45 - iter 4/11 - loss 0.07268000 - samples/sec: 205.71 - lr: 0.012500
2023-01-18 01:56:52,119 epoch 45 - iter 5/11 - loss 0.06762662 - samples/sec: 117.79 - lr: 0.012500
2023-01-18 01:56:52,293 epoch 45 - iter 6/11 - loss 0.06358288 - samples/sec: 185.51 - lr: 0.012500
2023-01-18 01:56:52,468 epoch 45 - iter 7/11 - loss 0.06336308 - samples/sec: 184.05 - lr: 0.012500
2023-01-18 01:56:52,651 epoch 45 - iter 8/11 - loss 0.06423237 - samples/sec: 175.71 - lr: 0.012500
2023-01-18 01:56:52,894 epoch 45 - iter 9/11 - loss 0.06358557 - samples/sec: 132.63 - lr: 0.012500
2023-01-18 01:56:53,186 epoch 45 - iter 10/11 - loss 0.06481758 - samples/sec: 109.93 - lr: 0.012500
2023-01-18 01:56:53,336 epoch 45 - iter 11/11 - loss 0.06362019 - samples/sec: 214.84 - lr: 0.012500
2023-01-18 01:56:53,337 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:53,338 EPOCH 45 done: loss 0.0636 - lr 0.012500
2023-01-18 01:56:54,455 Evaluating as a multi-label problem: False
2023-01-18 01:56:54,473 DEV : loss 0.05126776173710823 - f1-score (micro avg)  0.8772
2023-01-18 01:56:54,479 BAD EPOCHS (no improvement): 1
2023-01-18 01:56:54,481 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:54,636 epoch 46 - iter 1/11 - loss 0.07258816 - samples/sec: 207.07 - lr: 0.012500
2023-01-18 01:56:54,803 epoch 46 - iter 2/11 - loss 0.07232154 - samples/sec: 192.64 - lr: 0.012500
2023-01-18 01:56:54,974 epoch 46 - iter 3/11 - loss 0.06620729 - samples/sec: 188.48 - lr: 0.012500
2023-01-18 01:56:55,167 epoch 46 - iter 4/11 - loss 0.06337796 - samples/sec: 167.10 - lr: 0.012500
2023-01-18 01:56:55,352 epoch 46 - iter 5/11 - loss 0.06260868 - samples/sec: 173.61 - lr: 0.012500
2023-01-18 01:56:55,514 epoch 46 - iter 6/11 - loss 0.05862158 - samples/sec: 199.09 - lr: 0.012500
2023-01-18 01:56:55,687 epoch 46 - iter 7/11 - loss 0.06298738 - samples/sec: 186.05 - lr: 0.012500
2023-01-18 01:56:55,959 epoch 46 - iter 8/11 - loss 0.05997778 - samples/sec: 118.24 - lr: 0.012500
2023-01-18 01:56:56,144 epoch 46 - iter 9/11 - loss 0.06222018 - samples/sec: 174.03 - lr: 0.012500
2023-01-18 01:56:56,434 epoch 46 - iter 10/11 - loss 0.06120824 - samples/sec: 110.76 - lr: 0.012500
2023-01-18 01:56:56,635 epoch 46 - iter 11/11 - loss 0.06495628 - samples/sec: 160.24 - lr: 0.012500
2023-01-18 01:56:56,636 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:56,636 EPOCH 46 done: loss 0.0650 - lr 0.012500
2023-01-18 01:56:57,751 Evaluating as a multi-label problem: False
2023-01-18 01:56:57,768 DEV : loss 0.05009954422712326 - f1-score (micro avg)  0.877
2023-01-18 01:56:57,774 BAD EPOCHS (no improvement): 2
2023-01-18 01:56:57,776 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:57,954 epoch 47 - iter 1/11 - loss 0.03764802 - samples/sec: 180.26 - lr: 0.012500
2023-01-18 01:56:58,146 epoch 47 - iter 2/11 - loss 0.06681248 - samples/sec: 167.97 - lr: 0.012500
2023-01-18 01:56:58,306 epoch 47 - iter 3/11 - loss 0.06708128 - samples/sec: 201.52 - lr: 0.012500
2023-01-18 01:56:58,486 epoch 47 - iter 4/11 - loss 0.06366104 - samples/sec: 178.57 - lr: 0.012500
2023-01-18 01:56:58,674 epoch 47 - iter 5/11 - loss 0.06304029 - samples/sec: 170.84 - lr: 0.012500
2023-01-18 01:56:58,961 epoch 47 - iter 6/11 - loss 0.06310814 - samples/sec: 112.04 - lr: 0.012500
2023-01-18 01:56:59,118 epoch 47 - iter 7/11 - loss 0.06308963 - samples/sec: 205.39 - lr: 0.012500
2023-01-18 01:56:59,358 epoch 47 - iter 8/11 - loss 0.06184613 - samples/sec: 134.18 - lr: 0.012500
2023-01-18 01:56:59,599 epoch 47 - iter 9/11 - loss 0.06189184 - samples/sec: 133.14 - lr: 0.012500
2023-01-18 01:56:59,769 epoch 47 - iter 10/11 - loss 0.06240311 - samples/sec: 190.72 - lr: 0.012500
2023-01-18 01:56:59,902 epoch 47 - iter 11/11 - loss 0.06216083 - samples/sec: 242.01 - lr: 0.012500
2023-01-18 01:56:59,903 ----------------------------------------------------------------------------------------------------
2023-01-18 01:56:59,903 EPOCH 47 done: loss 0.0622 - lr 0.012500
2023-01-18 01:57:01,013 Evaluating as a multi-label problem: False
2023-01-18 01:57:01,030 DEV : loss 0.05013752356171608 - f1-score (micro avg)  0.876
2023-01-18 01:57:01,036 BAD EPOCHS (no improvement): 3
2023-01-18 01:57:01,038 ----------------------------------------------------------------------------------------------------
2023-01-18 01:57:01,282 epoch 48 - iter 1/11 - loss 0.07458670 - samples/sec: 131.66 - lr: 0.012500
2023-01-18 01:57:01,436 epoch 48 - iter 2/11 - loss 0.07416572 - samples/sec: 208.88 - lr: 0.012500
2023-01-18 01:57:01,677 epoch 48 - iter 3/11 - loss 0.06901005 - samples/sec: 133.32 - lr: 0.012500
2023-01-18 01:57:01,839 epoch 48 - iter 4/11 - loss 0.07596456 - samples/sec: 199.04 - lr: 0.012500
2023-01-18 01:57:02,367 epoch 48 - iter 5/11 - loss 0.07484374 - samples/sec: 60.80 - lr: 0.012500
2023-01-18 01:57:02,560 epoch 48 - iter 6/11 - loss 0.07165382 - samples/sec: 166.35 - lr: 0.012500
2023-01-18 01:57:02,733 epoch 48 - iter 7/11 - loss 0.07275269 - samples/sec: 186.16 - lr: 0.012500
2023-01-18 01:57:02,903 epoch 48 - iter 8/11 - loss 0.06932662 - samples/sec: 190.12 - lr: 0.012500
2023-01-18 01:57:03,178 epoch 48 - iter 9/11 - loss 0.06748375 - samples/sec: 116.63 - lr: 0.012500
2023-01-18 01:57:03,478 epoch 48 - iter 10/11 - loss 0.06614200 - samples/sec: 107.17 - lr: 0.012500
2023-01-18 01:57:03,635 epoch 48 - iter 11/11 - loss 0.06565000 - samples/sec: 205.94 - lr: 0.012500
2023-01-18 01:57:03,636 ----------------------------------------------------------------------------------------------------
2023-01-18 01:57:03,637 EPOCH 48 done: loss 0.0657 - lr 0.012500
2023-01-18 01:57:04,747 Evaluating as a multi-label problem: False
2023-01-18 01:57:04,764 DEV : loss 0.048184990882873535 - f1-score (micro avg)  0.8799
2023-01-18 01:57:04,770 Epoch    48: reducing learning rate of group 0 to 6.2500e-03.
2023-01-18 01:57:04,771 BAD EPOCHS (no improvement): 4
2023-01-18 01:57:04,772 ----------------------------------------------------------------------------------------------------
2023-01-18 01:57:04,970 epoch 49 - iter 1/11 - loss 0.07011687 - samples/sec: 162.85 - lr: 0.006250
2023-01-18 01:57:05,119 epoch 49 - iter 2/11 - loss 0.06664096 - samples/sec: 216.10 - lr: 0.006250
2023-01-18 01:57:05,415 epoch 49 - iter 3/11 - loss 0.06187576 - samples/sec: 108.29 - lr: 0.006250
2023-01-18 01:57:05,590 epoch 49 - iter 4/11 - loss 0.06339400 - samples/sec: 185.08 - lr: 0.006250
2023-01-18 01:57:05,747 epoch 49 - iter 5/11 - loss 0.06178323 - samples/sec: 205.11 - lr: 0.006250
2023-01-18 01:57:05,904 epoch 49 - iter 6/11 - loss 0.06166329 - samples/sec: 204.80 - lr: 0.006250
2023-01-18 01:57:06,180 epoch 49 - iter 7/11 - loss 0.05963473 - samples/sec: 116.50 - lr: 0.006250
2023-01-18 01:57:06,348 epoch 49 - iter 8/11 - loss 0.05810747 - samples/sec: 191.97 - lr: 0.006250
2023-01-18 01:57:06,533 epoch 49 - iter 9/11 - loss 0.05832700 - samples/sec: 174.25 - lr: 0.006250
2023-01-18 01:57:06,703 epoch 49 - iter 10/11 - loss 0.05761347 - samples/sec: 189.32 - lr: 0.006250
2023-01-18 01:57:06,908 epoch 49 - iter 11/11 - loss 0.06161286 - samples/sec: 156.88 - lr: 0.006250
2023-01-18 01:57:06,909 ----------------------------------------------------------------------------------------------------
2023-01-18 01:57:06,910 EPOCH 49 done: loss 0.0616 - lr 0.006250
2023-01-18 01:57:08,020 Evaluating as a multi-label problem: False
2023-01-18 01:57:08,037 DEV : loss 0.04870441555976868 - f1-score (micro avg)  0.8777
2023-01-18 01:57:08,043 BAD EPOCHS (no improvement): 1
2023-01-18 01:57:08,045 ----------------------------------------------------------------------------------------------------
2023-01-18 01:57:08,233 epoch 50 - iter 1/11 - loss 0.05700304 - samples/sec: 171.56 - lr: 0.006250
2023-01-18 01:57:08,476 epoch 50 - iter 2/11 - loss 0.06088928 - samples/sec: 132.30 - lr: 0.006250
2023-01-18 01:57:08,759 epoch 50 - iter 3/11 - loss 0.06316177 - samples/sec: 113.50 - lr: 0.006250
2023-01-18 01:57:08,934 epoch 50 - iter 4/11 - loss 0.06105379 - samples/sec: 184.56 - lr: 0.006250
2023-01-18 01:57:09,224 epoch 50 - iter 5/11 - loss 0.06206396 - samples/sec: 110.66 - lr: 0.006250
2023-01-18 01:57:09,468 epoch 50 - iter 6/11 - loss 0.06142790 - samples/sec: 131.81 - lr: 0.006250
2023-01-18 01:57:09,643 epoch 50 - iter 7/11 - loss 0.06439221 - samples/sec: 184.65 - lr: 0.006250
2023-01-18 01:57:09,795 epoch 50 - iter 8/11 - loss 0.06176018 - samples/sec: 210.95 - lr: 0.006250
2023-01-18 01:57:09,965 epoch 50 - iter 9/11 - loss 0.06227750 - samples/sec: 189.70 - lr: 0.006250
2023-01-18 01:57:10,150 epoch 50 - iter 10/11 - loss 0.06107915 - samples/sec: 174.04 - lr: 0.006250
2023-01-18 01:57:10,266 epoch 50 - iter 11/11 - loss 0.06144249 - samples/sec: 279.11 - lr: 0.006250
2023-01-18 01:57:10,267 ----------------------------------------------------------------------------------------------------
2023-01-18 01:57:10,267 EPOCH 50 done: loss 0.0614 - lr 0.006250
2023-01-18 01:57:11,375 Evaluating as a multi-label problem: False
2023-01-18 01:57:11,392 DEV : loss 0.05114128068089485 - f1-score (micro avg)  0.8788
2023-01-18 01:57:11,398 BAD EPOCHS (no improvement): 2
2023-01-18 01:57:16,439 ----------------------------------------------------------------------------------------------------
2023-01-18 01:57:16,441 loading file /home/mchou001/university-classifier/best-model.pt
2023-01-18 01:57:18,141 SequenceTagger predicts: Dictionary with 31 tags: O, S-author, B-author, E-author, I-author, S-university, B-university, E-university, I-university, S-title, B-title, E-title, I-title, S-degree, B-degree, E-degree, I-degree, S-year, B-year, E-year, I-year, S-program, B-program, E-program, I-program, S-advisor, B-advisor, E-advisor, I-advisor, <START>, <STOP>
2023-01-18 01:57:19,242 Evaluating as a multi-label problem: False
2023-01-18 01:57:19,255 0.952	0.952	0.952	0.9084000000000001
2023-01-18 01:57:19,256 
Results:
- F-score (micro) 0.952
- F-score (macro) 0.952
- Accuracy 0.9084000000000001

By class:
              precision    recall  f1-score   support

       title     1.0000    1.0000    1.0000        50
      author     0.9800    0.9800    0.9800        50
      degree     1.0000    1.0000    1.0000        50
  university     1.0000    1.0000    1.0000        50
        year     0.7800    0.7800    0.7800        50

   micro avg     0.9520    0.9520    0.9520       250
   macro avg     0.9520    0.9520    0.9520       250
weighted avg     0.9520    0.9520    0.9520       250

2023-01-18 01:57:19,256 ----------------------------------------------------------------------------------------------------
